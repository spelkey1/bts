{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Imports applicable to all scraping scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as BS\n",
    "import requests\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.firefox.firefox_binary import FirefoxBinary\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "from time import sleep\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for tr in table.find('thead').findAll('tr'):\n",
    "    headers = [c.text for c in tr.findAll('th')]\n",
    "headers.append('Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "headers = ['#', 'Season', 'Name', 'Team', \n",
    "            'G', 'PA', 'AB', 'H', '1B', '2B', \n",
    "            '3B', 'HR', 'R', 'RBI', 'BB', 'IBB', \n",
    "            'SO', 'HBP', 'SF', 'SH', 'GDP', 'SB', \n",
    "            'CS', 'AVG', 'Date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create list of days to iterate over\n",
    "start = datetime.date(year = 2015, month = 4, day = 5)\n",
    "end = datetime.date(year = 2015, month = 10, day = 4)\n",
    "date_range = []\n",
    "while start <= end:\n",
    "    date_range.append(start)\n",
    "    start += datetime.timedelta(days = 1)\n",
    "\n",
    "# Create master dataframe and open firefox\n",
    "master_df = pd.DataFrame(columns = headers)\n",
    "binary = FirefoxBinary(r'C:\\Program Files (x86)\\Mozilla Firefox\\firefox.exe')\n",
    "browser = webdriver.Firefox(firefox_binary=binary)\n",
    "\n",
    "# iterate through all days in range, and enter into url\n",
    "for day in date_range:\n",
    "    page = 0\n",
    "    url_list = ['http://www.fangraphs.com/leaderssplits.aspx?splitArr=&strgroup=season&statgroup=1&startDate=',\n",
    "           str(day),\n",
    "                '&endDate=',\n",
    "           str(day),\n",
    "            '&filter=&position=B&statType=player&autoPt=false&sort=22,1&pg=',\n",
    "           str(page)]\n",
    "    url = \"\".join(url_list)\n",
    "    browser.get(url)   \n",
    "    sleep(1)\n",
    "    \n",
    "    #pull html table from first page\n",
    "    soup = BS(browser.page_source, \"lxml\")\n",
    "    table = soup.find(attrs = {'class':\"table-splits\"})\n",
    "    body = table.find('tbody')\n",
    "    if body != None:\n",
    "        rows = body.findAll('tr')\n",
    "    else:\n",
    "        continue\n",
    "    \n",
    "    #parses data and appends to master dataframe\n",
    "    data = []\n",
    "    for tr in rows:\n",
    "        cols = tr.findAll('td')\n",
    "        row_text = [c.text for c in cols]\n",
    "        row_text.append(day)\n",
    "        data.append(row_text)\n",
    "    data_df = pd.DataFrame(data, columns=headers)\n",
    "    master_df = master_df.append(data_df)\n",
    "    \n",
    "    #iterate through all pages for given day\n",
    "    page = int(soup.find('span', attrs = {'class':\"table-control-total\"}).text)\n",
    "    for p in range(1,page):\n",
    "        \n",
    "        #scroll to bottom of page to prevent ad intereference\n",
    "        browser.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        \n",
    "        browser.find_element_by_class_name('material-icons' and 'next').click()\n",
    "        sleep(1)        \n",
    "        \n",
    "        #parses data and appends to master dataframe\n",
    "        data = []\n",
    "        soup = BS(browser.page_source, \"lxml\")\n",
    "        table = soup.find(attrs = {'class':\"table-splits\"})\n",
    "        body = table.find('tbody')\n",
    "        if body != None:\n",
    "            rows = body.findAll('tr')\n",
    "        else:\n",
    "            continue\n",
    "        for tr in rows:\n",
    "            cols = tr.findAll('td')\n",
    "            row_text = [c.text for c in cols]\n",
    "            row_text.append(day)\n",
    "            data.append(row_text)\n",
    "        data_df = pd.DataFrame(data, columns=headers)\n",
    "        master_df = master_df.append(data_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "master_df.to_csv('data/hitting/results_master.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "master_df = pd.DataFrame(columns = headers)\n",
    "for file in os.listdir():\n",
    "    if file.endswith('csv'):\n",
    "        master_df = master_df.append(pd.read_csv(file, index_col = 0))\n",
    "master_df.to_csv('results_master.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Home"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#get headers\n",
    "url = \"http://www.fangraphs.com/leaderssplits.aspx?splitArr=7&strgroup=season&statgroup=2&startDate=2016-04-03&endDate=2016-06-10&filter=&position=B&statType=player&autoPt=false&sort=16,1&pg=0\"\n",
    "binary = FirefoxBinary(r'C:\\Program Files (x86)\\Mozilla Firefox\\firefox.exe')\n",
    "browser = webdriver.Firefox(firefox_binary=binary)\n",
    "browser.get(url)   \n",
    "sleep(1)\n",
    "soup = BS(browser.page_source, \"lxml\")\n",
    "table = soup.find(attrs = {'class':\"table-splits\"})\n",
    "for tr in table.find('thead').findAll('tr'):\n",
    "    headers = [c.text for c in tr.findAll('th')]\n",
    "headers.append('Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "headers = ['#',\n",
    " 'Season',\n",
    " 'Name',\n",
    " 'Team',\n",
    " 'PA',\n",
    " 'BB%',\n",
    " 'K%',\n",
    " 'BB/K',\n",
    " 'AVG',\n",
    " 'OBP',\n",
    " 'SLG',\n",
    " 'OPS',\n",
    " 'ISO',\n",
    " 'BABIP',\n",
    " 'wRC',\n",
    " 'wRAA',\n",
    " 'wOBA',\n",
    " 'wRC+',\n",
    " 'Date']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create list of days to iterate over\n",
    "start = datetime.date(year = 2015, month = 4, day = 5)\n",
    "end = datetime.date(year = 2015, month = 10, day = 4)\n",
    "date_range = []\n",
    "while start <= end:\n",
    "    date_range.append(start)\n",
    "    start += datetime.timedelta(days = 1)\n",
    "\n",
    "# Create master dataframe and open firefox\n",
    "master_df = pd.DataFrame(columns = headers)\n",
    "binary = FirefoxBinary(r'C:\\Program Files (x86)\\Mozilla Firefox\\firefox.exe')\n",
    "browser = webdriver.Firefox(firefox_binary=binary)\n",
    "\n",
    "# iterate through all days in range, and enter in url\n",
    "for day in date_range:\n",
    "    page = 0\n",
    "    url_list = ['http://www.fangraphs.com/leaderssplits.aspx?splitArr=7&strgroup=season&statgroup=2&startDate=2015-04-05&endDate=',\n",
    "           str(day),\n",
    "            '&filter=&position=B&statType=player&autoPt=false&sort=16,1&pg=',\n",
    "           str(page)]\n",
    "    url = \"\".join(url_list)\n",
    "    browser.get(url)   \n",
    "    table = None\n",
    "    \n",
    "    #pull html table from first page\n",
    "    while table == None:\n",
    "        soup = BS(browser.page_source, \"lxml\")\n",
    "        table = soup.find(attrs = {'class':\"table-splits\"})\n",
    "        sleep(1)\n",
    "    body = table.find('tbody')\n",
    "    if body != None:\n",
    "        rows = body.findAll('tr')\n",
    "    else:\n",
    "        continue\n",
    "    \n",
    "    #parses data and appends to master dataframe\n",
    "    data = []\n",
    "    for tr in rows:\n",
    "        cols = tr.findAll('td')\n",
    "        row_text = [c.text for c in cols]\n",
    "        row_text.append(day)\n",
    "        data.append(row_text)\n",
    "    data_df = pd.DataFrame(data, columns=headers)\n",
    "    master_df = master_df.append(data_df)\n",
    "    \n",
    "    #iterate through all pages for given day\n",
    "    page = int(soup.find('span', attrs = {'class':\"table-control-total\"}).text)\n",
    "    for p in range(1,page):\n",
    "        \n",
    "        #scroll to bottom of page to prevent ad intereference\n",
    "        browser.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        \n",
    "        browser.find_element_by_class_name('material-icons' and 'next').click()\n",
    "        sleep(1)             \n",
    "        \n",
    "        #parses data and appends to master dataframe\n",
    "        data = []\n",
    "        soup = BS(browser.page_source, \"lxml\")\n",
    "        table = soup.find(attrs = {'class':\"table-splits\"})\n",
    "        body = table.find('tbody')\n",
    "        if body != None:\n",
    "            rows = body.findAll('tr')\n",
    "        else:\n",
    "            continue\n",
    "        for tr in rows:\n",
    "            cols = tr.findAll('td')\n",
    "            row_text = [c.text for c in cols]\n",
    "            row_text.append(day)\n",
    "            data.append(row_text)\n",
    "        data_df = pd.DataFrame(data, columns=headers)\n",
    "        master_df = master_df.append(data_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "master_df.to_csv('data/hitting/season_home_master.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "master_df = pd.DataFrame(columns = headers)\n",
    "for file in os.listdir('data/hitting/'):\n",
    "    if file.startswith('season_home'):\n",
    "        master_df = master_df.append(pd.read_csv('data/hitting/'+file, index_col = 0))\n",
    "master_df.to_csv('data/hitting/season_home_master.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Away\n",
    "### Season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create list of days to iterate over\n",
    "start = datetime.date(year = 2015, month = 4, day = 5)\n",
    "end = datetime.date(year = 2015, month = 10, day = 4)\n",
    "date_range = []\n",
    "while start <= end:\n",
    "    date_range.append(start)\n",
    "    start += datetime.timedelta(days = 1)\n",
    "\n",
    "# Create master dataframe and open firefox\n",
    "master_df = pd.DataFrame(columns = headers)\n",
    "binary = FirefoxBinary(r'C:\\Program Files (x86)\\Mozilla Firefox\\firefox.exe')\n",
    "browser = webdriver.Firefox(firefox_binary=binary)\n",
    "\n",
    "# iterate through all days in range, and enter in url\n",
    "for day in date_range:\n",
    "    page = 0\n",
    "    url_list = ['http://www.fangraphs.com/leaderssplits.aspx?splitArr=8&strgroup=season&statgroup=2&startDate=2015-04-05&endDate=',\n",
    "           str(day),\n",
    "            '&filter=&position=B&statType=player&autoPt=false&sort=16,1&pg=',\n",
    "           str(page)]\n",
    "    url = \"\".join(url_list)\n",
    "    browser.get(url)   \n",
    "    table = None\n",
    "    \n",
    "    #pull html table from first page\n",
    "    while table == None:\n",
    "        soup = BS(browser.page_source, \"lxml\")\n",
    "        table = soup.find(attrs = {'class':\"table-splits\"})\n",
    "        sleep(1)\n",
    "    body = table.find('tbody')\n",
    "    if body != None:\n",
    "        rows = body.findAll('tr')\n",
    "    else:\n",
    "        continue\n",
    "    \n",
    "    #parses data and appends to master dataframe\n",
    "    data = []\n",
    "    for tr in rows:\n",
    "        cols = tr.findAll('td')\n",
    "        row_text = [c.text for c in cols]\n",
    "        row_text.append(day)\n",
    "        data.append(row_text)\n",
    "    data_df = pd.DataFrame(data, columns=headers)\n",
    "    master_df = master_df.append(data_df)\n",
    "    \n",
    "    #iterate through all pages for given day\n",
    "    page = int(soup.find('span', attrs = {'class':\"table-control-total\"}).text)\n",
    "    for p in range(1,page):\n",
    "        \n",
    "        #scroll to bottom of page to prevent ad intereference\n",
    "        browser.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")        \n",
    "        \n",
    "        browser.find_element_by_class_name('material-icons' and 'next').click()\n",
    "        sleep(1)\n",
    "        \n",
    "        #parses data and appends to master dataframe\n",
    "        data = []\n",
    "        soup = BS(browser.page_source, \"lxml\")\n",
    "        table = soup.find(attrs = {'class':\"table-splits\"})\n",
    "        body = table.find('tbody')\n",
    "        if body != None:\n",
    "            rows = body.findAll('tr')\n",
    "        else:\n",
    "            continue\n",
    "        for tr in rows:\n",
    "            cols = tr.findAll('td')\n",
    "            row_text = [c.text for c in cols]\n",
    "            row_text.append(day)\n",
    "            data.append(row_text)\n",
    "        data_df = pd.DataFrame(data, columns=headers)\n",
    "        master_df = master_df.append(data_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "master_df.to_csv('data/hitting/season_away_master.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "master_df = pd.DataFrame(columns = headers)\n",
    "for file in os.listdir('data/hitting/'):\n",
    "    if file.startswith('season_away'):\n",
    "        master_df = master_df.append(pd.read_csv('data/hitting/'+file, index_col = 0))\n",
    "master_df.to_csv('data/hitting/season_away_master.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lefties\n",
    "### Season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create list of days to iterate over\n",
    "start = datetime.date(year = 2015, month = 7, day = 2)\n",
    "end = datetime.date(year = 2015, month = 10, day = 4)\n",
    "date_range = []\n",
    "while start <= end:\n",
    "    date_range.append(start)\n",
    "    start += datetime.timedelta(days = 1)\n",
    "\n",
    "# Create master dataframe and open firefox\n",
    "master_df = pd.DataFrame(columns = headers)\n",
    "binary = FirefoxBinary(r'C:\\Program Files (x86)\\Mozilla Firefox\\firefox.exe')\n",
    "browser = webdriver.Firefox(firefox_binary=binary)\n",
    "\n",
    "# iterate through all days in range, and enter in url\n",
    "for day in date_range:\n",
    "    page = 0\n",
    "    url_list = ['http://www.fangraphs.com/leaderssplits.aspx?splitArr=1&strgroup=season&statgroup=2&startDate=2015-04-05&endDate=',\n",
    "           str(day),\n",
    "            '&filter=&position=B&statType=player&autoPt=false&sort=16,1&pg=',\n",
    "           str(page)]\n",
    "    url = \"\".join(url_list)\n",
    "    browser.get(url)   \n",
    "    table = None\n",
    "    \n",
    "    #pull html table from first page\n",
    "    while table == None:\n",
    "        soup = BS(browser.page_source, \"lxml\")\n",
    "        table = soup.find(attrs = {'class':\"table-splits\"})\n",
    "        sleep(1)\n",
    "    body = table.find('tbody')\n",
    "    if body != None:\n",
    "        rows = body.findAll('tr')\n",
    "    else:\n",
    "        continue\n",
    "    \n",
    "    #parses data and appends to master dataframe\n",
    "    data = []\n",
    "    for tr in rows:\n",
    "        cols = tr.findAll('td')\n",
    "        row_text = [c.text for c in cols]\n",
    "        row_text.append(day)\n",
    "        data.append(row_text)\n",
    "    data_df = pd.DataFrame(data, columns=headers)\n",
    "    master_df = master_df.append(data_df)\n",
    "    \n",
    "    #iterate through all pages for given day\n",
    "    page = int(soup.find('span', attrs = {'class':\"table-control-total\"}).text)\n",
    "    for p in range(1,page):\n",
    "        \n",
    "        #scroll to bottom of page to prevent ad interference\n",
    "        browser.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        \n",
    "        browser.find_element_by_class_name('material-icons' and 'next').click()\n",
    "        sleep(1)\n",
    "        \n",
    "        #parses data and appends to master dataframe\n",
    "        data = []\n",
    "        soup = BS(browser.page_source, \"lxml\")\n",
    "        table = soup.find(attrs = {'class':\"table-splits\"})\n",
    "        body = table.find('tbody')\n",
    "        if body != None:\n",
    "            rows = body.findAll('tr')\n",
    "        else:\n",
    "            continue\n",
    "        for tr in rows:\n",
    "            cols = tr.findAll('td')\n",
    "            row_text = [c.text for c in cols]\n",
    "            row_text.append(day)\n",
    "            data.append(row_text)\n",
    "        data_df = pd.DataFrame(data, columns=headers)\n",
    "        master_df = master_df.append(data_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#</th>\n",
       "      <th>Season</th>\n",
       "      <th>Name</th>\n",
       "      <th>Team</th>\n",
       "      <th>PA</th>\n",
       "      <th>BB%</th>\n",
       "      <th>K%</th>\n",
       "      <th>BB/K</th>\n",
       "      <th>AVG</th>\n",
       "      <th>OBP</th>\n",
       "      <th>SLG</th>\n",
       "      <th>OPS</th>\n",
       "      <th>ISO</th>\n",
       "      <th>BABIP</th>\n",
       "      <th>wRC</th>\n",
       "      <th>wRAA</th>\n",
       "      <th>wOBA</th>\n",
       "      <th>wRC+</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2015</td>\n",
       "      <td>Kyle Blanks</td>\n",
       "      <td>TEX</td>\n",
       "      <td>27</td>\n",
       "      <td>0.0%</td>\n",
       "      <td>25.9%</td>\n",
       "      <td>0.0</td>\n",
       "      <td>.333</td>\n",
       "      <td>.333</td>\n",
       "      <td>.778</td>\n",
       "      <td>1.111</td>\n",
       "      <td>.444</td>\n",
       "      <td>.353</td>\n",
       "      <td>6</td>\n",
       "      <td>3.3</td>\n",
       "      <td>.467</td>\n",
       "      <td>199</td>\n",
       "      <td>2015-07-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2015</td>\n",
       "      <td>Jason Marquis</td>\n",
       "      <td>CIN</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0%</td>\n",
       "      <td>33.3%</td>\n",
       "      <td>0.0</td>\n",
       "      <td>.000</td>\n",
       "      <td>.000</td>\n",
       "      <td>.000</td>\n",
       "      <td>.000</td>\n",
       "      <td>.000</td>\n",
       "      <td>.000</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.5</td>\n",
       "      <td>.000</td>\n",
       "      <td>-100</td>\n",
       "      <td>2015-07-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2015</td>\n",
       "      <td>Will Venable</td>\n",
       "      <td>SDP</td>\n",
       "      <td>21</td>\n",
       "      <td>4.8%</td>\n",
       "      <td>28.6%</td>\n",
       "      <td>0.2</td>\n",
       "      <td>.250</td>\n",
       "      <td>.286</td>\n",
       "      <td>.300</td>\n",
       "      <td>.586</td>\n",
       "      <td>.050</td>\n",
       "      <td>.357</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.9</td>\n",
       "      <td>.260</td>\n",
       "      <td>64</td>\n",
       "      <td>2015-07-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2015</td>\n",
       "      <td>Bartolo Colon</td>\n",
       "      <td>NYM</td>\n",
       "      <td>7</td>\n",
       "      <td>0.0%</td>\n",
       "      <td>42.9%</td>\n",
       "      <td>0.0</td>\n",
       "      <td>.143</td>\n",
       "      <td>.143</td>\n",
       "      <td>.143</td>\n",
       "      <td>.286</td>\n",
       "      <td>.000</td>\n",
       "      <td>.250</td>\n",
       "      <td>-0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>.126</td>\n",
       "      <td>-27</td>\n",
       "      <td>2015-07-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2015</td>\n",
       "      <td>Victor Martinez</td>\n",
       "      <td>DET</td>\n",
       "      <td>45</td>\n",
       "      <td>8.9%</td>\n",
       "      <td>4.4%</td>\n",
       "      <td>2.0</td>\n",
       "      <td>.410</td>\n",
       "      <td>.467</td>\n",
       "      <td>.564</td>\n",
       "      <td>1.031</td>\n",
       "      <td>.154</td>\n",
       "      <td>.405</td>\n",
       "      <td>9</td>\n",
       "      <td>4.4</td>\n",
       "      <td>.436</td>\n",
       "      <td>181</td>\n",
       "      <td>2015-07-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>2015</td>\n",
       "      <td>Juan Uribe</td>\n",
       "      <td>2 Tms</td>\n",
       "      <td>39</td>\n",
       "      <td>10.3%</td>\n",
       "      <td>17.9%</td>\n",
       "      <td>0.6</td>\n",
       "      <td>.286</td>\n",
       "      <td>.359</td>\n",
       "      <td>.543</td>\n",
       "      <td>.902</td>\n",
       "      <td>.257</td>\n",
       "      <td>.280</td>\n",
       "      <td>6</td>\n",
       "      <td>2.1</td>\n",
       "      <td>.380</td>\n",
       "      <td>145</td>\n",
       "      <td>2015-07-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>2015</td>\n",
       "      <td>A.J. Burnett</td>\n",
       "      <td>PIT</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0%</td>\n",
       "      <td>50.0%</td>\n",
       "      <td>0.0</td>\n",
       "      <td>.250</td>\n",
       "      <td>.250</td>\n",
       "      <td>.250</td>\n",
       "      <td>.500</td>\n",
       "      <td>.000</td>\n",
       "      <td>.500</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>.220</td>\n",
       "      <td>36</td>\n",
       "      <td>2015-07-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>2015</td>\n",
       "      <td>Carlos Beltran</td>\n",
       "      <td>NYY</td>\n",
       "      <td>75</td>\n",
       "      <td>8.0%</td>\n",
       "      <td>21.3%</td>\n",
       "      <td>0.4</td>\n",
       "      <td>.239</td>\n",
       "      <td>.307</td>\n",
       "      <td>.403</td>\n",
       "      <td>.710</td>\n",
       "      <td>.164</td>\n",
       "      <td>.280</td>\n",
       "      <td>8</td>\n",
       "      <td>-0.6</td>\n",
       "      <td>.303</td>\n",
       "      <td>90</td>\n",
       "      <td>2015-07-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>2015</td>\n",
       "      <td>Brandon Barnes</td>\n",
       "      <td>COL</td>\n",
       "      <td>27</td>\n",
       "      <td>7.4%</td>\n",
       "      <td>25.9%</td>\n",
       "      <td>0.3</td>\n",
       "      <td>.200</td>\n",
       "      <td>.259</td>\n",
       "      <td>.200</td>\n",
       "      <td>.459</td>\n",
       "      <td>.000</td>\n",
       "      <td>.278</td>\n",
       "      <td>1</td>\n",
       "      <td>-2.1</td>\n",
       "      <td>.214</td>\n",
       "      <td>12</td>\n",
       "      <td>2015-07-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>2015</td>\n",
       "      <td>Adrian Beltre</td>\n",
       "      <td>TEX</td>\n",
       "      <td>84</td>\n",
       "      <td>4.8%</td>\n",
       "      <td>9.5%</td>\n",
       "      <td>0.5</td>\n",
       "      <td>.263</td>\n",
       "      <td>.298</td>\n",
       "      <td>.450</td>\n",
       "      <td>.748</td>\n",
       "      <td>.188</td>\n",
       "      <td>.261</td>\n",
       "      <td>10</td>\n",
       "      <td>0.3</td>\n",
       "      <td>.317</td>\n",
       "      <td>96</td>\n",
       "      <td>2015-07-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>2015</td>\n",
       "      <td>Torii Hunter</td>\n",
       "      <td>MIN</td>\n",
       "      <td>94</td>\n",
       "      <td>6.4%</td>\n",
       "      <td>22.3%</td>\n",
       "      <td>0.3</td>\n",
       "      <td>.244</td>\n",
       "      <td>.298</td>\n",
       "      <td>.407</td>\n",
       "      <td>.705</td>\n",
       "      <td>.163</td>\n",
       "      <td>.286</td>\n",
       "      <td>10</td>\n",
       "      <td>-0.8</td>\n",
       "      <td>.302</td>\n",
       "      <td>88</td>\n",
       "      <td>2015-07-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>2015</td>\n",
       "      <td>Kyle Lohse</td>\n",
       "      <td>MIL</td>\n",
       "      <td>9</td>\n",
       "      <td>0.0%</td>\n",
       "      <td>33.3%</td>\n",
       "      <td>0.0</td>\n",
       "      <td>.111</td>\n",
       "      <td>.111</td>\n",
       "      <td>.111</td>\n",
       "      <td>.222</td>\n",
       "      <td>.000</td>\n",
       "      <td>.167</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.5</td>\n",
       "      <td>.098</td>\n",
       "      <td>-54</td>\n",
       "      <td>2015-07-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>2015</td>\n",
       "      <td>David Ortiz</td>\n",
       "      <td>BOS</td>\n",
       "      <td>89</td>\n",
       "      <td>1.1%</td>\n",
       "      <td>21.3%</td>\n",
       "      <td>0.1</td>\n",
       "      <td>.128</td>\n",
       "      <td>.135</td>\n",
       "      <td>.198</td>\n",
       "      <td>.333</td>\n",
       "      <td>.070</td>\n",
       "      <td>.147</td>\n",
       "      <td>-2</td>\n",
       "      <td>-12.1</td>\n",
       "      <td>.143</td>\n",
       "      <td>-26</td>\n",
       "      <td>2015-07-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>2015</td>\n",
       "      <td>A.J. Pierzynski</td>\n",
       "      <td>ATL</td>\n",
       "      <td>32</td>\n",
       "      <td>6.3%</td>\n",
       "      <td>12.5%</td>\n",
       "      <td>0.5</td>\n",
       "      <td>.207</td>\n",
       "      <td>.281</td>\n",
       "      <td>.276</td>\n",
       "      <td>.557</td>\n",
       "      <td>.069</td>\n",
       "      <td>.240</td>\n",
       "      <td>2</td>\n",
       "      <td>-1.5</td>\n",
       "      <td>.254</td>\n",
       "      <td>56</td>\n",
       "      <td>2015-07-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>2015</td>\n",
       "      <td>Todd Frazier</td>\n",
       "      <td>CIN</td>\n",
       "      <td>87</td>\n",
       "      <td>5.7%</td>\n",
       "      <td>21.8%</td>\n",
       "      <td>0.3</td>\n",
       "      <td>.280</td>\n",
       "      <td>.322</td>\n",
       "      <td>.683</td>\n",
       "      <td>1.005</td>\n",
       "      <td>.402</td>\n",
       "      <td>.259</td>\n",
       "      <td>17</td>\n",
       "      <td>7.5</td>\n",
       "      <td>.421</td>\n",
       "      <td>169</td>\n",
       "      <td>2015-07-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>2015</td>\n",
       "      <td>Brandon Phillips</td>\n",
       "      <td>CIN</td>\n",
       "      <td>71</td>\n",
       "      <td>5.6%</td>\n",
       "      <td>5.6%</td>\n",
       "      <td>1.0</td>\n",
       "      <td>.313</td>\n",
       "      <td>.352</td>\n",
       "      <td>.388</td>\n",
       "      <td>.740</td>\n",
       "      <td>.075</td>\n",
       "      <td>.323</td>\n",
       "      <td>8</td>\n",
       "      <td>0.5</td>\n",
       "      <td>.321</td>\n",
       "      <td>101</td>\n",
       "      <td>2015-07-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>2015</td>\n",
       "      <td>Randy Choate</td>\n",
       "      <td>STL</td>\n",
       "      <td>1</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>0.0%</td>\n",
       "      <td>1.0</td>\n",
       "      <td>.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>.000</td>\n",
       "      <td>.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>.687</td>\n",
       "      <td>354</td>\n",
       "      <td>2015-07-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>2015</td>\n",
       "      <td>Brennan Boesch</td>\n",
       "      <td>CIN</td>\n",
       "      <td>8</td>\n",
       "      <td>12.5%</td>\n",
       "      <td>62.5%</td>\n",
       "      <td>0.2</td>\n",
       "      <td>.143</td>\n",
       "      <td>.250</td>\n",
       "      <td>.143</td>\n",
       "      <td>.393</td>\n",
       "      <td>.000</td>\n",
       "      <td>.500</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.7</td>\n",
       "      <td>.196</td>\n",
       "      <td>15</td>\n",
       "      <td>2015-07-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>2015</td>\n",
       "      <td>Tim Hudson</td>\n",
       "      <td>SFG</td>\n",
       "      <td>8</td>\n",
       "      <td>12.5%</td>\n",
       "      <td>25.0%</td>\n",
       "      <td>0.5</td>\n",
       "      <td>.200</td>\n",
       "      <td>.333</td>\n",
       "      <td>.400</td>\n",
       "      <td>.733</td>\n",
       "      <td>.200</td>\n",
       "      <td>.333</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>.324</td>\n",
       "      <td>109</td>\n",
       "      <td>2015-07-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>2015</td>\n",
       "      <td>Marlon Byrd</td>\n",
       "      <td>CIN</td>\n",
       "      <td>58</td>\n",
       "      <td>12.1%</td>\n",
       "      <td>22.4%</td>\n",
       "      <td>0.5</td>\n",
       "      <td>.294</td>\n",
       "      <td>.379</td>\n",
       "      <td>.549</td>\n",
       "      <td>.928</td>\n",
       "      <td>.255</td>\n",
       "      <td>.343</td>\n",
       "      <td>10</td>\n",
       "      <td>3.7</td>\n",
       "      <td>.393</td>\n",
       "      <td>150</td>\n",
       "      <td>2015-07-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>2015</td>\n",
       "      <td>Jimmy Rollins</td>\n",
       "      <td>LAD</td>\n",
       "      <td>55</td>\n",
       "      <td>5.5%</td>\n",
       "      <td>12.7%</td>\n",
       "      <td>0.4</td>\n",
       "      <td>.275</td>\n",
       "      <td>.315</td>\n",
       "      <td>.373</td>\n",
       "      <td>.687</td>\n",
       "      <td>.098</td>\n",
       "      <td>.302</td>\n",
       "      <td>6</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>.302</td>\n",
       "      <td>94</td>\n",
       "      <td>2015-07-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>2015</td>\n",
       "      <td>Aramis Ramirez</td>\n",
       "      <td>MIL</td>\n",
       "      <td>51</td>\n",
       "      <td>9.8%</td>\n",
       "      <td>13.7%</td>\n",
       "      <td>0.7</td>\n",
       "      <td>.133</td>\n",
       "      <td>.216</td>\n",
       "      <td>.356</td>\n",
       "      <td>.571</td>\n",
       "      <td>.222</td>\n",
       "      <td>.083</td>\n",
       "      <td>3</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>.239</td>\n",
       "      <td>43</td>\n",
       "      <td>2015-07-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>2015</td>\n",
       "      <td>Daniel Dorn</td>\n",
       "      <td>ARI</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0%</td>\n",
       "      <td>0.0%</td>\n",
       "      <td>0.0</td>\n",
       "      <td>.000</td>\n",
       "      <td>.000</td>\n",
       "      <td>.000</td>\n",
       "      <td>.000</td>\n",
       "      <td>.000</td>\n",
       "      <td>.000</td>\n",
       "      <td>-0</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>.000</td>\n",
       "      <td>-100</td>\n",
       "      <td>2015-07-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>2015</td>\n",
       "      <td>Willie Bloomquist</td>\n",
       "      <td>SEA</td>\n",
       "      <td>41</td>\n",
       "      <td>4.9%</td>\n",
       "      <td>12.2%</td>\n",
       "      <td>0.4</td>\n",
       "      <td>.184</td>\n",
       "      <td>.244</td>\n",
       "      <td>.211</td>\n",
       "      <td>.454</td>\n",
       "      <td>.026</td>\n",
       "      <td>.212</td>\n",
       "      <td>1</td>\n",
       "      <td>-3.4</td>\n",
       "      <td>.211</td>\n",
       "      <td>30</td>\n",
       "      <td>2015-07-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>2015</td>\n",
       "      <td>Ichiro Suzuki</td>\n",
       "      <td>MIA</td>\n",
       "      <td>46</td>\n",
       "      <td>6.5%</td>\n",
       "      <td>13.0%</td>\n",
       "      <td>0.5</td>\n",
       "      <td>.310</td>\n",
       "      <td>.356</td>\n",
       "      <td>.381</td>\n",
       "      <td>.737</td>\n",
       "      <td>.071</td>\n",
       "      <td>.343</td>\n",
       "      <td>6</td>\n",
       "      <td>0.5</td>\n",
       "      <td>.327</td>\n",
       "      <td>107</td>\n",
       "      <td>2015-07-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>2015</td>\n",
       "      <td>Jerome Williams</td>\n",
       "      <td>PHI</td>\n",
       "      <td>8</td>\n",
       "      <td>12.5%</td>\n",
       "      <td>25.0%</td>\n",
       "      <td>0.5</td>\n",
       "      <td>.000</td>\n",
       "      <td>.125</td>\n",
       "      <td>.000</td>\n",
       "      <td>.125</td>\n",
       "      <td>.000</td>\n",
       "      <td>.000</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.5</td>\n",
       "      <td>.086</td>\n",
       "      <td>-58</td>\n",
       "      <td>2015-07-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>2015</td>\n",
       "      <td>Andrew Romine</td>\n",
       "      <td>DET</td>\n",
       "      <td>12</td>\n",
       "      <td>8.3%</td>\n",
       "      <td>50.0%</td>\n",
       "      <td>0.2</td>\n",
       "      <td>.182</td>\n",
       "      <td>.250</td>\n",
       "      <td>.455</td>\n",
       "      <td>.705</td>\n",
       "      <td>.273</td>\n",
       "      <td>.250</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>.303</td>\n",
       "      <td>89</td>\n",
       "      <td>2015-07-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>2015</td>\n",
       "      <td>Albert Pujols</td>\n",
       "      <td>LAA</td>\n",
       "      <td>68</td>\n",
       "      <td>7.4%</td>\n",
       "      <td>11.8%</td>\n",
       "      <td>0.6</td>\n",
       "      <td>.210</td>\n",
       "      <td>.265</td>\n",
       "      <td>.468</td>\n",
       "      <td>.732</td>\n",
       "      <td>.258</td>\n",
       "      <td>.176</td>\n",
       "      <td>7</td>\n",
       "      <td>-0.8</td>\n",
       "      <td>.299</td>\n",
       "      <td>92</td>\n",
       "      <td>2015-07-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>2015</td>\n",
       "      <td>Chris Johnson</td>\n",
       "      <td>ATL</td>\n",
       "      <td>36</td>\n",
       "      <td>2.8%</td>\n",
       "      <td>22.2%</td>\n",
       "      <td>0.1</td>\n",
       "      <td>.400</td>\n",
       "      <td>.417</td>\n",
       "      <td>.543</td>\n",
       "      <td>.960</td>\n",
       "      <td>.143</td>\n",
       "      <td>.500</td>\n",
       "      <td>7</td>\n",
       "      <td>2.9</td>\n",
       "      <td>.415</td>\n",
       "      <td>167</td>\n",
       "      <td>2015-07-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>2015</td>\n",
       "      <td>Carl Crawford</td>\n",
       "      <td>LAD</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0%</td>\n",
       "      <td>33.3%</td>\n",
       "      <td>0.0</td>\n",
       "      <td>.167</td>\n",
       "      <td>.167</td>\n",
       "      <td>.167</td>\n",
       "      <td>.333</td>\n",
       "      <td>.000</td>\n",
       "      <td>.250</td>\n",
       "      <td>-0</td>\n",
       "      <td>-0.8</td>\n",
       "      <td>.147</td>\n",
       "      <td>-12</td>\n",
       "      <td>2015-07-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>802</td>\n",
       "      <td>2015</td>\n",
       "      <td>Carlos Correa</td>\n",
       "      <td>HOU</td>\n",
       "      <td>140</td>\n",
       "      <td>10.0%</td>\n",
       "      <td>15.0%</td>\n",
       "      <td>0.7</td>\n",
       "      <td>.274</td>\n",
       "      <td>.343</td>\n",
       "      <td>.556</td>\n",
       "      <td>.899</td>\n",
       "      <td>.282</td>\n",
       "      <td>.260</td>\n",
       "      <td>23</td>\n",
       "      <td>7.2</td>\n",
       "      <td>.378</td>\n",
       "      <td>144</td>\n",
       "      <td>2015-10-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>803</td>\n",
       "      <td>2015</td>\n",
       "      <td>Jorge Soler</td>\n",
       "      <td>CHC</td>\n",
       "      <td>92</td>\n",
       "      <td>16.3%</td>\n",
       "      <td>31.5%</td>\n",
       "      <td>0.5</td>\n",
       "      <td>.240</td>\n",
       "      <td>.370</td>\n",
       "      <td>.360</td>\n",
       "      <td>.730</td>\n",
       "      <td>.120</td>\n",
       "      <td>.356</td>\n",
       "      <td>11</td>\n",
       "      <td>0.4</td>\n",
       "      <td>.318</td>\n",
       "      <td>100</td>\n",
       "      <td>2015-10-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>804</td>\n",
       "      <td>2015</td>\n",
       "      <td>Yasiel Puig</td>\n",
       "      <td>LAD</td>\n",
       "      <td>79</td>\n",
       "      <td>13.9%</td>\n",
       "      <td>19.0%</td>\n",
       "      <td>0.7</td>\n",
       "      <td>.279</td>\n",
       "      <td>.380</td>\n",
       "      <td>.544</td>\n",
       "      <td>.924</td>\n",
       "      <td>.265</td>\n",
       "      <td>.292</td>\n",
       "      <td>14</td>\n",
       "      <td>5.0</td>\n",
       "      <td>.393</td>\n",
       "      <td>156</td>\n",
       "      <td>2015-10-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>805</td>\n",
       "      <td>2015</td>\n",
       "      <td>Wilmer Difo</td>\n",
       "      <td>WSN</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0%</td>\n",
       "      <td>0.0%</td>\n",
       "      <td>0.0</td>\n",
       "      <td>.000</td>\n",
       "      <td>.000</td>\n",
       "      <td>.000</td>\n",
       "      <td>.000</td>\n",
       "      <td>.000</td>\n",
       "      <td>.000</td>\n",
       "      <td>-0</td>\n",
       "      <td>-0.8</td>\n",
       "      <td>.000</td>\n",
       "      <td>-100</td>\n",
       "      <td>2015-10-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>806</td>\n",
       "      <td>2015</td>\n",
       "      <td>Dilson Herrera</td>\n",
       "      <td>NYM</td>\n",
       "      <td>24</td>\n",
       "      <td>16.7%</td>\n",
       "      <td>29.2%</td>\n",
       "      <td>0.6</td>\n",
       "      <td>.250</td>\n",
       "      <td>.375</td>\n",
       "      <td>.350</td>\n",
       "      <td>.725</td>\n",
       "      <td>.100</td>\n",
       "      <td>.385</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>.314</td>\n",
       "      <td>101</td>\n",
       "      <td>2015-10-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>807</td>\n",
       "      <td>2015</td>\n",
       "      <td>Henry Urrutia</td>\n",
       "      <td>BAL</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0%</td>\n",
       "      <td>0.0%</td>\n",
       "      <td>0.0</td>\n",
       "      <td>.000</td>\n",
       "      <td>.000</td>\n",
       "      <td>.000</td>\n",
       "      <td>.000</td>\n",
       "      <td>.000</td>\n",
       "      <td>.000</td>\n",
       "      <td>-0</td>\n",
       "      <td>-0.8</td>\n",
       "      <td>.000</td>\n",
       "      <td>-100</td>\n",
       "      <td>2015-10-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>808</td>\n",
       "      <td>2015</td>\n",
       "      <td>Adam Conley</td>\n",
       "      <td>MIA</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0%</td>\n",
       "      <td>33.3%</td>\n",
       "      <td>0.0</td>\n",
       "      <td>.000</td>\n",
       "      <td>.000</td>\n",
       "      <td>.000</td>\n",
       "      <td>.000</td>\n",
       "      <td>.000</td>\n",
       "      <td>.000</td>\n",
       "      <td>-0</td>\n",
       "      <td>-0.8</td>\n",
       "      <td>.000</td>\n",
       "      <td>-100</td>\n",
       "      <td>2015-10-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>809</td>\n",
       "      <td>2015</td>\n",
       "      <td>Severino Gonzalez</td>\n",
       "      <td>PHI</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0%</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>0.0</td>\n",
       "      <td>.000</td>\n",
       "      <td>.000</td>\n",
       "      <td>.000</td>\n",
       "      <td>.000</td>\n",
       "      <td>.000</td>\n",
       "      <td>.000</td>\n",
       "      <td>-0</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>.000</td>\n",
       "      <td>-100</td>\n",
       "      <td>2015-10-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>810</td>\n",
       "      <td>2015</td>\n",
       "      <td>Buck Farmer</td>\n",
       "      <td>DET</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0%</td>\n",
       "      <td>0.0%</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>2.000</td>\n",
       "      <td>.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>.881</td>\n",
       "      <td>488</td>\n",
       "      <td>2015-10-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>811</td>\n",
       "      <td>2015</td>\n",
       "      <td>Michael Lorenzen</td>\n",
       "      <td>CIN</td>\n",
       "      <td>14</td>\n",
       "      <td>0.0%</td>\n",
       "      <td>28.6%</td>\n",
       "      <td>0.0</td>\n",
       "      <td>.154</td>\n",
       "      <td>.154</td>\n",
       "      <td>.308</td>\n",
       "      <td>.462</td>\n",
       "      <td>.154</td>\n",
       "      <td>.222</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.4</td>\n",
       "      <td>.190</td>\n",
       "      <td>11</td>\n",
       "      <td>2015-10-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>812</td>\n",
       "      <td>2015</td>\n",
       "      <td>Zack Godley</td>\n",
       "      <td>ARI</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0%</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>0.0</td>\n",
       "      <td>.000</td>\n",
       "      <td>.000</td>\n",
       "      <td>.000</td>\n",
       "      <td>.000</td>\n",
       "      <td>.000</td>\n",
       "      <td>.000</td>\n",
       "      <td>-0</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>.000</td>\n",
       "      <td>-100</td>\n",
       "      <td>2015-10-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>813</td>\n",
       "      <td>2015</td>\n",
       "      <td>Jon Gray</td>\n",
       "      <td>COL</td>\n",
       "      <td>7</td>\n",
       "      <td>14.3%</td>\n",
       "      <td>42.9%</td>\n",
       "      <td>0.3</td>\n",
       "      <td>.000</td>\n",
       "      <td>.143</td>\n",
       "      <td>.000</td>\n",
       "      <td>.143</td>\n",
       "      <td>.000</td>\n",
       "      <td>.000</td>\n",
       "      <td>-0</td>\n",
       "      <td>-1.2</td>\n",
       "      <td>.098</td>\n",
       "      <td>-68</td>\n",
       "      <td>2015-10-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>814</td>\n",
       "      <td>2015</td>\n",
       "      <td>Andrew Heaney</td>\n",
       "      <td>LAA</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0%</td>\n",
       "      <td>60.0%</td>\n",
       "      <td>0.0</td>\n",
       "      <td>.000</td>\n",
       "      <td>.000</td>\n",
       "      <td>.000</td>\n",
       "      <td>.000</td>\n",
       "      <td>.000</td>\n",
       "      <td>.000</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.3</td>\n",
       "      <td>.000</td>\n",
       "      <td>-100</td>\n",
       "      <td>2015-10-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>815</td>\n",
       "      <td>2015</td>\n",
       "      <td>Kris Bryant</td>\n",
       "      <td>CHC</td>\n",
       "      <td>145</td>\n",
       "      <td>13.1%</td>\n",
       "      <td>36.6%</td>\n",
       "      <td>0.4</td>\n",
       "      <td>.246</td>\n",
       "      <td>.345</td>\n",
       "      <td>.452</td>\n",
       "      <td>.797</td>\n",
       "      <td>.206</td>\n",
       "      <td>.373</td>\n",
       "      <td>20</td>\n",
       "      <td>4.0</td>\n",
       "      <td>.348</td>\n",
       "      <td>121</td>\n",
       "      <td>2015-10-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>816</td>\n",
       "      <td>2015</td>\n",
       "      <td>Daniel Castro</td>\n",
       "      <td>ATL</td>\n",
       "      <td>43</td>\n",
       "      <td>2.3%</td>\n",
       "      <td>9.3%</td>\n",
       "      <td>0.3</td>\n",
       "      <td>.268</td>\n",
       "      <td>.286</td>\n",
       "      <td>.463</td>\n",
       "      <td>.749</td>\n",
       "      <td>.195</td>\n",
       "      <td>.257</td>\n",
       "      <td>5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>.321</td>\n",
       "      <td>103</td>\n",
       "      <td>2015-10-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>817</td>\n",
       "      <td>2015</td>\n",
       "      <td>Dariel Alvarez</td>\n",
       "      <td>BAL</td>\n",
       "      <td>24</td>\n",
       "      <td>4.2%</td>\n",
       "      <td>25.0%</td>\n",
       "      <td>0.2</td>\n",
       "      <td>.261</td>\n",
       "      <td>.292</td>\n",
       "      <td>.435</td>\n",
       "      <td>.726</td>\n",
       "      <td>.174</td>\n",
       "      <td>.313</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>.314</td>\n",
       "      <td>95</td>\n",
       "      <td>2015-10-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>818</td>\n",
       "      <td>2015</td>\n",
       "      <td>Alex Guerrero</td>\n",
       "      <td>LAD</td>\n",
       "      <td>84</td>\n",
       "      <td>2.4%</td>\n",
       "      <td>23.8%</td>\n",
       "      <td>0.1</td>\n",
       "      <td>.237</td>\n",
       "      <td>.262</td>\n",
       "      <td>.388</td>\n",
       "      <td>.649</td>\n",
       "      <td>.150</td>\n",
       "      <td>.276</td>\n",
       "      <td>7</td>\n",
       "      <td>-2.2</td>\n",
       "      <td>.280</td>\n",
       "      <td>79</td>\n",
       "      <td>2015-10-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>819</td>\n",
       "      <td>2015</td>\n",
       "      <td>Jose Abreu</td>\n",
       "      <td>CHW</td>\n",
       "      <td>157</td>\n",
       "      <td>7.6%</td>\n",
       "      <td>19.7%</td>\n",
       "      <td>0.4</td>\n",
       "      <td>.232</td>\n",
       "      <td>.306</td>\n",
       "      <td>.352</td>\n",
       "      <td>.658</td>\n",
       "      <td>.120</td>\n",
       "      <td>.278</td>\n",
       "      <td>15</td>\n",
       "      <td>-3.2</td>\n",
       "      <td>.288</td>\n",
       "      <td>79</td>\n",
       "      <td>2015-10-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>820</td>\n",
       "      <td>2015</td>\n",
       "      <td>Masahiro Tanaka</td>\n",
       "      <td>NYY</td>\n",
       "      <td>4</td>\n",
       "      <td>25.0%</td>\n",
       "      <td>25.0%</td>\n",
       "      <td>1.0</td>\n",
       "      <td>.000</td>\n",
       "      <td>.250</td>\n",
       "      <td>.000</td>\n",
       "      <td>.250</td>\n",
       "      <td>.000</td>\n",
       "      <td>.000</td>\n",
       "      <td>-0</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>.172</td>\n",
       "      <td>-1</td>\n",
       "      <td>2015-10-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>821</td>\n",
       "      <td>2015</td>\n",
       "      <td>Odrisamer Despaigne</td>\n",
       "      <td>SDP</td>\n",
       "      <td>9</td>\n",
       "      <td>0.0%</td>\n",
       "      <td>22.2%</td>\n",
       "      <td>0.0</td>\n",
       "      <td>.125</td>\n",
       "      <td>.125</td>\n",
       "      <td>.125</td>\n",
       "      <td>.250</td>\n",
       "      <td>.000</td>\n",
       "      <td>.167</td>\n",
       "      <td>-0</td>\n",
       "      <td>-1.5</td>\n",
       "      <td>.110</td>\n",
       "      <td>-39</td>\n",
       "      <td>2015-10-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>822</td>\n",
       "      <td>2015</td>\n",
       "      <td>Carlos Rodon</td>\n",
       "      <td>CHW</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0%</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>0.0</td>\n",
       "      <td>.000</td>\n",
       "      <td>.000</td>\n",
       "      <td>.000</td>\n",
       "      <td>.000</td>\n",
       "      <td>.000</td>\n",
       "      <td>.000</td>\n",
       "      <td>-0</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>.000</td>\n",
       "      <td>-100</td>\n",
       "      <td>2015-10-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>823</td>\n",
       "      <td>2015</td>\n",
       "      <td>Aaron Nola</td>\n",
       "      <td>PHI</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0%</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>0.0</td>\n",
       "      <td>.000</td>\n",
       "      <td>.000</td>\n",
       "      <td>.000</td>\n",
       "      <td>.000</td>\n",
       "      <td>.000</td>\n",
       "      <td>.000</td>\n",
       "      <td>-0</td>\n",
       "      <td>-0.8</td>\n",
       "      <td>.000</td>\n",
       "      <td>-100</td>\n",
       "      <td>2015-10-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>824</td>\n",
       "      <td>2015</td>\n",
       "      <td>Trea Turner</td>\n",
       "      <td>WSN</td>\n",
       "      <td>9</td>\n",
       "      <td>11.1%</td>\n",
       "      <td>11.1%</td>\n",
       "      <td>1.0</td>\n",
       "      <td>.375</td>\n",
       "      <td>.444</td>\n",
       "      <td>.375</td>\n",
       "      <td>.819</td>\n",
       "      <td>.000</td>\n",
       "      <td>.429</td>\n",
       "      <td>1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>.370</td>\n",
       "      <td>135</td>\n",
       "      <td>2015-10-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>825</td>\n",
       "      <td>2015</td>\n",
       "      <td>Michael Conforto</td>\n",
       "      <td>NYM</td>\n",
       "      <td>15</td>\n",
       "      <td>6.7%</td>\n",
       "      <td>20.0%</td>\n",
       "      <td>0.3</td>\n",
       "      <td>.214</td>\n",
       "      <td>.267</td>\n",
       "      <td>.214</td>\n",
       "      <td>.481</td>\n",
       "      <td>.000</td>\n",
       "      <td>.273</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.1</td>\n",
       "      <td>.222</td>\n",
       "      <td>39</td>\n",
       "      <td>2015-10-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>826</td>\n",
       "      <td>2015</td>\n",
       "      <td>Kyle Schwarber</td>\n",
       "      <td>CHC</td>\n",
       "      <td>61</td>\n",
       "      <td>8.2%</td>\n",
       "      <td>44.3%</td>\n",
       "      <td>0.2</td>\n",
       "      <td>.143</td>\n",
       "      <td>.213</td>\n",
       "      <td>.268</td>\n",
       "      <td>.481</td>\n",
       "      <td>.125</td>\n",
       "      <td>.222</td>\n",
       "      <td>2</td>\n",
       "      <td>-4.7</td>\n",
       "      <td>.217</td>\n",
       "      <td>31</td>\n",
       "      <td>2015-10-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>827</td>\n",
       "      <td>2015</td>\n",
       "      <td>Rusney Castillo</td>\n",
       "      <td>BOS</td>\n",
       "      <td>94</td>\n",
       "      <td>4.3%</td>\n",
       "      <td>16.0%</td>\n",
       "      <td>0.3</td>\n",
       "      <td>.318</td>\n",
       "      <td>.351</td>\n",
       "      <td>.466</td>\n",
       "      <td>.817</td>\n",
       "      <td>.148</td>\n",
       "      <td>.361</td>\n",
       "      <td>13</td>\n",
       "      <td>2.9</td>\n",
       "      <td>.352</td>\n",
       "      <td>119</td>\n",
       "      <td>2015-10-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>828</td>\n",
       "      <td>2015</td>\n",
       "      <td>Raisel Iglesias</td>\n",
       "      <td>CIN</td>\n",
       "      <td>7</td>\n",
       "      <td>0.0%</td>\n",
       "      <td>57.1%</td>\n",
       "      <td>0.0</td>\n",
       "      <td>.000</td>\n",
       "      <td>.000</td>\n",
       "      <td>.000</td>\n",
       "      <td>.000</td>\n",
       "      <td>.000</td>\n",
       "      <td>.000</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.8</td>\n",
       "      <td>.000</td>\n",
       "      <td>-100</td>\n",
       "      <td>2015-10-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>829</td>\n",
       "      <td>2015</td>\n",
       "      <td>Yasmany Tomas</td>\n",
       "      <td>ARI</td>\n",
       "      <td>119</td>\n",
       "      <td>5.9%</td>\n",
       "      <td>21.0%</td>\n",
       "      <td>0.3</td>\n",
       "      <td>.279</td>\n",
       "      <td>.319</td>\n",
       "      <td>.477</td>\n",
       "      <td>.797</td>\n",
       "      <td>.198</td>\n",
       "      <td>.325</td>\n",
       "      <td>16</td>\n",
       "      <td>2.6</td>\n",
       "      <td>.341</td>\n",
       "      <td>111</td>\n",
       "      <td>2015-10-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>830</td>\n",
       "      <td>2015</td>\n",
       "      <td>Jung Ho Kang</td>\n",
       "      <td>PIT</td>\n",
       "      <td>97</td>\n",
       "      <td>9.3%</td>\n",
       "      <td>24.7%</td>\n",
       "      <td>0.4</td>\n",
       "      <td>.238</td>\n",
       "      <td>.340</td>\n",
       "      <td>.381</td>\n",
       "      <td>.721</td>\n",
       "      <td>.143</td>\n",
       "      <td>.298</td>\n",
       "      <td>12</td>\n",
       "      <td>0.8</td>\n",
       "      <td>.323</td>\n",
       "      <td>107</td>\n",
       "      <td>2015-10-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>831</td>\n",
       "      <td>2015</td>\n",
       "      <td>Hector Olivera</td>\n",
       "      <td>ATL</td>\n",
       "      <td>17</td>\n",
       "      <td>11.8%</td>\n",
       "      <td>29.4%</td>\n",
       "      <td>0.4</td>\n",
       "      <td>.067</td>\n",
       "      <td>.176</td>\n",
       "      <td>.067</td>\n",
       "      <td>.243</td>\n",
       "      <td>.000</td>\n",
       "      <td>.100</td>\n",
       "      <td>-1</td>\n",
       "      <td>-2.5</td>\n",
       "      <td>.133</td>\n",
       "      <td>-27</td>\n",
       "      <td>2015-10-04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>70790 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      # Season                 Name   Team   PA     BB%      K% BB/K    AVG  \\\n",
       "0     1   2015          Kyle Blanks    TEX   27    0.0%   25.9%  0.0   .333   \n",
       "1     2   2015        Jason Marquis    CIN    6    0.0%   33.3%  0.0   .000   \n",
       "2     3   2015         Will Venable    SDP   21    4.8%   28.6%  0.2   .250   \n",
       "3     4   2015        Bartolo Colon    NYM    7    0.0%   42.9%  0.0   .143   \n",
       "4     5   2015      Victor Martinez    DET   45    8.9%    4.4%  2.0   .410   \n",
       "5     6   2015           Juan Uribe  2 Tms   39   10.3%   17.9%  0.6   .286   \n",
       "6     7   2015         A.J. Burnett    PIT    4    0.0%   50.0%  0.0   .250   \n",
       "7     8   2015       Carlos Beltran    NYY   75    8.0%   21.3%  0.4   .239   \n",
       "8     9   2015       Brandon Barnes    COL   27    7.4%   25.9%  0.3   .200   \n",
       "9    10   2015        Adrian Beltre    TEX   84    4.8%    9.5%  0.5   .263   \n",
       "10   11   2015         Torii Hunter    MIN   94    6.4%   22.3%  0.3   .244   \n",
       "11   12   2015           Kyle Lohse    MIL    9    0.0%   33.3%  0.0   .111   \n",
       "12   13   2015          David Ortiz    BOS   89    1.1%   21.3%  0.1   .128   \n",
       "13   14   2015      A.J. Pierzynski    ATL   32    6.3%   12.5%  0.5   .207   \n",
       "14   15   2015         Todd Frazier    CIN   87    5.7%   21.8%  0.3   .280   \n",
       "15   16   2015     Brandon Phillips    CIN   71    5.6%    5.6%  1.0   .313   \n",
       "16   17   2015         Randy Choate    STL    1  100.0%    0.0%  1.0   .000   \n",
       "17   18   2015       Brennan Boesch    CIN    8   12.5%   62.5%  0.2   .143   \n",
       "18   19   2015           Tim Hudson    SFG    8   12.5%   25.0%  0.5   .200   \n",
       "19   20   2015          Marlon Byrd    CIN   58   12.1%   22.4%  0.5   .294   \n",
       "20   21   2015        Jimmy Rollins    LAD   55    5.5%   12.7%  0.4   .275   \n",
       "21   22   2015       Aramis Ramirez    MIL   51    9.8%   13.7%  0.7   .133   \n",
       "22   23   2015          Daniel Dorn    ARI    1    0.0%    0.0%  0.0   .000   \n",
       "23   24   2015    Willie Bloomquist    SEA   41    4.9%   12.2%  0.4   .184   \n",
       "24   25   2015        Ichiro Suzuki    MIA   46    6.5%   13.0%  0.5   .310   \n",
       "25   26   2015      Jerome Williams    PHI    8   12.5%   25.0%  0.5   .000   \n",
       "26   27   2015        Andrew Romine    DET   12    8.3%   50.0%  0.2   .182   \n",
       "27   28   2015        Albert Pujols    LAA   68    7.4%   11.8%  0.6   .210   \n",
       "28   29   2015        Chris Johnson    ATL   36    2.8%   22.2%  0.1   .400   \n",
       "29   30   2015        Carl Crawford    LAD    6    0.0%   33.3%  0.0   .167   \n",
       "..  ...    ...                  ...    ...  ...     ...     ...  ...    ...   \n",
       "21  802   2015        Carlos Correa    HOU  140   10.0%   15.0%  0.7   .274   \n",
       "22  803   2015          Jorge Soler    CHC   92   16.3%   31.5%  0.5   .240   \n",
       "23  804   2015          Yasiel Puig    LAD   79   13.9%   19.0%  0.7   .279   \n",
       "24  805   2015          Wilmer Difo    WSN    3    0.0%    0.0%  0.0   .000   \n",
       "25  806   2015       Dilson Herrera    NYM   24   16.7%   29.2%  0.6   .250   \n",
       "26  807   2015        Henry Urrutia    BAL    3    0.0%    0.0%  0.0   .000   \n",
       "27  808   2015          Adam Conley    MIA    3    0.0%   33.3%  0.0   .000   \n",
       "28  809   2015    Severino Gonzalez    PHI    1    0.0%  100.0%  0.0   .000   \n",
       "29  810   2015          Buck Farmer    DET    1    0.0%    0.0%  0.0  1.000   \n",
       "0   811   2015     Michael Lorenzen    CIN   14    0.0%   28.6%  0.0   .154   \n",
       "1   812   2015          Zack Godley    ARI    1    0.0%  100.0%  0.0   .000   \n",
       "2   813   2015             Jon Gray    COL    7   14.3%   42.9%  0.3   .000   \n",
       "3   814   2015        Andrew Heaney    LAA    5    0.0%   60.0%  0.0   .000   \n",
       "4   815   2015          Kris Bryant    CHC  145   13.1%   36.6%  0.4   .246   \n",
       "5   816   2015        Daniel Castro    ATL   43    2.3%    9.3%  0.3   .268   \n",
       "6   817   2015       Dariel Alvarez    BAL   24    4.2%   25.0%  0.2   .261   \n",
       "7   818   2015        Alex Guerrero    LAD   84    2.4%   23.8%  0.1   .237   \n",
       "8   819   2015           Jose Abreu    CHW  157    7.6%   19.7%  0.4   .232   \n",
       "9   820   2015      Masahiro Tanaka    NYY    4   25.0%   25.0%  1.0   .000   \n",
       "10  821   2015  Odrisamer Despaigne    SDP    9    0.0%   22.2%  0.0   .125   \n",
       "11  822   2015         Carlos Rodon    CHW    1    0.0%  100.0%  0.0   .000   \n",
       "12  823   2015           Aaron Nola    PHI    3    0.0%  100.0%  0.0   .000   \n",
       "13  824   2015          Trea Turner    WSN    9   11.1%   11.1%  1.0   .375   \n",
       "14  825   2015     Michael Conforto    NYM   15    6.7%   20.0%  0.3   .214   \n",
       "15  826   2015       Kyle Schwarber    CHC   61    8.2%   44.3%  0.2   .143   \n",
       "16  827   2015      Rusney Castillo    BOS   94    4.3%   16.0%  0.3   .318   \n",
       "17  828   2015      Raisel Iglesias    CIN    7    0.0%   57.1%  0.0   .000   \n",
       "18  829   2015        Yasmany Tomas    ARI  119    5.9%   21.0%  0.3   .279   \n",
       "19  830   2015         Jung Ho Kang    PIT   97    9.3%   24.7%  0.4   .238   \n",
       "20  831   2015       Hector Olivera    ATL   17   11.8%   29.4%  0.4   .067   \n",
       "\n",
       "      OBP    SLG    OPS   ISO  BABIP wRC   wRAA  wOBA  wRC+        Date  \n",
       "0    .333   .778  1.111  .444   .353   6    3.3  .467   199  2015-07-02  \n",
       "1    .000   .000   .000  .000   .000  -1   -1.5  .000  -100  2015-07-02  \n",
       "2    .286   .300   .586  .050   .357   1   -0.9  .260    64  2015-07-02  \n",
       "3    .143   .143   .286  .000   .250  -0   -1.0  .126   -27  2015-07-02  \n",
       "4    .467   .564  1.031  .154   .405   9    4.4  .436   181  2015-07-02  \n",
       "5    .359   .543   .902  .257   .280   6    2.1  .380   145  2015-07-02  \n",
       "6    .250   .250   .500  .000   .500   0   -0.3  .220    36  2015-07-02  \n",
       "7    .307   .403   .710  .164   .280   8   -0.6  .303    90  2015-07-02  \n",
       "8    .259   .200   .459  .000   .278   1   -2.1  .214    12  2015-07-02  \n",
       "9    .298   .450   .748  .188   .261  10    0.3  .317    96  2015-07-02  \n",
       "10   .298   .407   .705  .163   .286  10   -0.8  .302    88  2015-07-02  \n",
       "11   .111   .111   .222  .000   .167  -1   -1.5  .098   -54  2015-07-02  \n",
       "12   .135   .198   .333  .070   .147  -2  -12.1  .143   -26  2015-07-02  \n",
       "13   .281   .276   .557  .069   .240   2   -1.5  .254    56  2015-07-02  \n",
       "14   .322   .683  1.005  .402   .259  17    7.5  .421   169  2015-07-02  \n",
       "15   .352   .388   .740  .075   .323   8    0.5  .321   101  2015-07-02  \n",
       "16  1.000   .000  1.000  .000   .000   0    0.3  .687   354  2015-07-02  \n",
       "17   .250   .143   .393  .000   .500   0   -0.7  .196    15  2015-07-02  \n",
       "18   .333   .400   .733  .200   .333   1    0.1  .324   109  2015-07-02  \n",
       "19   .379   .549   .928  .255   .343  10    3.7  .393   150  2015-07-02  \n",
       "20   .315   .373   .687  .098   .302   6   -0.5  .302    94  2015-07-02  \n",
       "21   .216   .356   .571  .222   .083   3   -3.0  .239    43  2015-07-02  \n",
       "22   .000   .000   .000  .000   .000  -0   -0.3  .000  -100  2015-07-02  \n",
       "23   .244   .211   .454  .026   .212   1   -3.4  .211    30  2015-07-02  \n",
       "24   .356   .381   .737  .071   .343   6    0.5  .327   107  2015-07-02  \n",
       "25   .125   .000   .125  .000   .000  -1   -1.5  .086   -58  2015-07-02  \n",
       "26   .250   .455   .705  .273   .250   1   -0.1  .303    89  2015-07-02  \n",
       "27   .265   .468   .732  .258   .176   7   -0.8  .299    92  2015-07-02  \n",
       "28   .417   .543   .960  .143   .500   7    2.9  .415   167  2015-07-02  \n",
       "29   .167   .167   .333  .000   .250  -0   -0.8  .147   -12  2015-07-02  \n",
       "..    ...    ...    ...   ...    ...  ..    ...   ...   ...         ...  \n",
       "21   .343   .556   .899  .282   .260  23    7.2  .378   144  2015-10-04  \n",
       "22   .370   .360   .730  .120   .356  11    0.4  .318   100  2015-10-04  \n",
       "23   .380   .544   .924  .265   .292  14    5.0  .393   156  2015-10-04  \n",
       "24   .000   .000   .000  .000   .000  -0   -0.8  .000  -100  2015-10-04  \n",
       "25   .375   .350   .725  .100   .385   3    0.0  .314   101  2015-10-04  \n",
       "26   .000   .000   .000  .000   .000  -0   -0.8  .000  -100  2015-10-04  \n",
       "27   .000   .000   .000  .000   .000  -0   -0.8  .000  -100  2015-10-04  \n",
       "28   .000   .000   .000  .000   .000  -0   -0.3  .000  -100  2015-10-04  \n",
       "29  1.000  1.000  2.000  .000  1.000   1    0.5  .881   488  2015-10-04  \n",
       "0    .154   .308   .462  .154   .222   0   -1.4  .190    11  2015-10-04  \n",
       "1    .000   .000   .000  .000   .000  -0   -0.3  .000  -100  2015-10-04  \n",
       "2    .143   .000   .143  .000   .000  -0   -1.2  .098   -68  2015-10-04  \n",
       "3    .000   .000   .000  .000   .000  -1   -1.3  .000  -100  2015-10-04  \n",
       "4    .345   .452   .797  .206   .373  20    4.0  .348   121  2015-10-04  \n",
       "5    .286   .463   .749  .195   .257   5    0.3  .321   103  2015-10-04  \n",
       "6    .292   .435   .726  .174   .313   3    0.0  .314    95  2015-10-04  \n",
       "7    .262   .388   .649  .150   .276   7   -2.2  .280    79  2015-10-04  \n",
       "8    .306   .352   .658  .120   .278  15   -3.2  .288    79  2015-10-04  \n",
       "9    .250   .000   .250  .000   .000  -0   -0.5  .172    -1  2015-10-04  \n",
       "10   .125   .125   .250  .000   .167  -0   -1.5  .110   -39  2015-10-04  \n",
       "11   .000   .000   .000  .000   .000  -0   -0.3  .000  -100  2015-10-04  \n",
       "12   .000   .000   .000  .000   .000  -0   -0.8  .000  -100  2015-10-04  \n",
       "13   .444   .375   .819  .000   .429   1    0.4  .370   135  2015-10-04  \n",
       "14   .267   .214   .481  .000   .273   1   -1.1  .222    39  2015-10-04  \n",
       "15   .213   .268   .481  .125   .222   2   -4.7  .217    31  2015-10-04  \n",
       "16   .351   .466   .817  .148   .361  13    2.9  .352   119  2015-10-04  \n",
       "17   .000   .000   .000  .000   .000  -1   -1.8  .000  -100  2015-10-04  \n",
       "18   .319   .477   .797  .198   .325  16    2.6  .341   111  2015-10-04  \n",
       "19   .340   .381   .721  .143   .298  12    0.8  .323   107  2015-10-04  \n",
       "20   .176   .067   .243  .000   .100  -1   -2.5  .133   -27  2015-10-04  \n",
       "\n",
       "[70790 rows x 19 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "master_df.append(master_df1).to_csv('data/hitting/season_lefties_master.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "master_df.to_csv('data/hitting/season_lefties_09_02_to_10_02.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "master_df = pd.DataFrame(columns = headers)\n",
    "for file in os.listdir('data/hitting/'):\n",
    "    if file.startswith('season_lefties'):\n",
    "        master_df = master_df.append(pd.read_csv('data/hitting/'+file, index_col = 0))\n",
    "master_df.to_csv('data/hitting/season_lefties_master.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Rightes\n",
    "### Season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create list of days to iterate over\n",
    "start = datetime.date(year = 2015, month = 4, day = 5)\n",
    "end = datetime.date(year = 2015, month = 10, day = 4)\n",
    "date_range = []\n",
    "while start <= end:\n",
    "    date_range.append(start)\n",
    "    start += datetime.timedelta(days = 1)\n",
    "\n",
    "# Create master dataframe and open firefox\n",
    "master_df = pd.DataFrame(columns = headers)\n",
    "binary = FirefoxBinary(r'C:\\Program Files (x86)\\Mozilla Firefox\\firefox.exe')\n",
    "browser = webdriver.Firefox(firefox_binary=binary)\n",
    "\n",
    "# iterate through all days in range, and enter in url\n",
    "for day in date_range:\n",
    "    page = 0\n",
    "    url_list = ['http://www.fangraphs.com/leaderssplits.aspx?splitArr=2&strgroup=season&statgroup=2&startDate=2015-04-05&endDate=',\n",
    "           str(day),\n",
    "            '&filter=&position=B&statType=player&autoPt=false&sort=16,1&pg=',\n",
    "           str(page)]\n",
    "    url = \"\".join(url_list)\n",
    "    browser.get(url)   \n",
    "    table = None\n",
    "    \n",
    "    #pull html table from first page\n",
    "    while table == None:\n",
    "        soup = BS(browser.page_source, \"lxml\")\n",
    "        table = soup.find(attrs = {'class':\"table-splits\"})\n",
    "        sleep(1)\n",
    "    body = table.find('tbody')\n",
    "    if body != None:\n",
    "        rows = body.findAll('tr')\n",
    "    else:\n",
    "        continue\n",
    "    \n",
    "    #parses data and appends to master dataframe\n",
    "    data = []\n",
    "    for tr in rows:\n",
    "        cols = tr.findAll('td')\n",
    "        row_text = [c.text for c in cols]\n",
    "        row_text.append(day)\n",
    "        data.append(row_text)\n",
    "    data_df = pd.DataFrame(data, columns=headers)\n",
    "    master_df = master_df.append(data_df)\n",
    "    \n",
    "    #iterate through all pages for given day\n",
    "    page = int(soup.find('span', attrs = {'class':\"table-control-total\"}).text)\n",
    "    for p in range(1,page):\n",
    "        \n",
    "        #scroll to bottom of page to prevent ad interference\n",
    "        browser.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")        \n",
    "        \n",
    "        browser.find_element_by_class_name('material-icons' and 'next').click()\n",
    "        sleep(1)\n",
    "        \n",
    "        #parses data and appends to master dataframe\n",
    "        data = []\n",
    "        soup = BS(browser.page_source, \"lxml\")\n",
    "        table = soup.find(attrs = {'class':\"table-splits\"})\n",
    "        body = table.find('tbody')\n",
    "        if body != None:\n",
    "            rows = body.findAll('tr')\n",
    "        else:\n",
    "            continue\n",
    "        for tr in rows:\n",
    "            cols = tr.findAll('td')\n",
    "            row_text = [c.text for c in cols]\n",
    "            row_text.append(day)\n",
    "            data.append(row_text)\n",
    "        data_df = pd.DataFrame(data, columns=headers)\n",
    "        master_df = master_df.append(data_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "master_df.to_csv('data/hitting/season_righties_master.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "master_df = pd.DataFrame(columns = headers)\n",
    "for file in os.listdir('data/hitting/'):\n",
    "    if file.startswith('season_righties'):\n",
    "        master_df = master_df.append(pd.read_csv('data/hitting/'+file, index_col = 0))\n",
    "master_df.to_csv('data/hitting/season_righties_master.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Past 7 Days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.date(2015, 9, 27)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datetime.date(year = 2015, month = 10, day = 4) - datetime.timedelta(days = 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create list of days to iterate over\n",
    "start = datetime.date(year = 2015, month = 4, day = 5)\n",
    "end = datetime.date(year = 2015, month = 9, day = 27)\n",
    "date_range = []\n",
    "while start <= end:\n",
    "    date_range.append(start)\n",
    "    start += datetime.timedelta(days = 1)\n",
    "\n",
    "# Create master dataframe and open firefox\n",
    "master_df = pd.DataFrame(columns = headers)\n",
    "binary = FirefoxBinary(r'C:\\Program Files (x86)\\Mozilla Firefox\\firefox.exe')\n",
    "browser = webdriver.Firefox(firefox_binary=binary)\n",
    "\n",
    "# iterate through all days in range, and enter in url\n",
    "for day in date_range:\n",
    "    page = 0\n",
    "    url_list = ['http://www.fangraphs.com/leaderssplits.aspx?splitArr=&strgroup=season&statgroup=2&startDate=',\n",
    "           str(day),'&endDate=',str(day + datetime.timedelta(days = 7)),\n",
    "            '&filter=&position=B&statType=player&autoPt=false&sort=16,1&pg=',\n",
    "           str(page)]\n",
    "    url = \"\".join(url_list)\n",
    "    browser.get(url)   \n",
    "    table = None\n",
    "    \n",
    "    #pull html table from first page\n",
    "    while table == None:\n",
    "        soup = BS(browser.page_source, \"lxml\")\n",
    "        table = soup.find(attrs = {'class':\"table-splits\"})\n",
    "        sleep(1)\n",
    "    body = table.find('tbody')\n",
    "    if body != None:\n",
    "        rows = body.findAll('tr')\n",
    "    else:\n",
    "        continue\n",
    "    \n",
    "    #parses data and appends to master dataframe\n",
    "    data = []\n",
    "    for tr in rows:\n",
    "        cols = tr.findAll('td')\n",
    "        row_text = [c.text for c in cols]\n",
    "        row_text.append(day + datetime.timedelta(days = 7))\n",
    "        data.append(row_text)\n",
    "    data_df = pd.DataFrame(data, columns=headers)\n",
    "    master_df = master_df.append(data_df)\n",
    "    \n",
    "    #iterate through all pages for given day\n",
    "    page = int(soup.find('span', attrs = {'class':\"table-control-total\"}).text)\n",
    "    for p in range(1,page):\n",
    "        \n",
    "        #scroll to bottom of page to prevent ad interference\n",
    "        browser.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")          \n",
    "        \n",
    "        browser.find_element_by_class_name('material-icons' and 'next').click()\n",
    "        sleep(1)\n",
    "        \n",
    "        #parses data and appends to master dataframe\n",
    "        data = []\n",
    "        soup = BS(browser.page_source, \"lxml\")\n",
    "        table = soup.find(attrs = {'class':\"table-splits\"})\n",
    "        body = table.find('tbody')\n",
    "        if body != None:\n",
    "            rows = body.findAll('tr')\n",
    "        else:\n",
    "            continue\n",
    "        for tr in rows:\n",
    "            cols = tr.findAll('td')\n",
    "            row_text = [c.text for c in cols]\n",
    "            row_text.append(day + datetime.timedelta(days = 7))\n",
    "            data.append(row_text)\n",
    "        data_df = pd.DataFrame(data, columns=headers)\n",
    "        master_df = master_df.append(data_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "master_df.to_csv('data/hitting/week_master.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "master_df = pd.DataFrame(columns = headers)\n",
    "for file in os.listdir('data/hitting/'):\n",
    "    if file.startswith('week'):\n",
    "        master_df = master_df.append(pd.read_csv('data/hitting/'+file, index_col = 0))\n",
    "master_df.to_csv('data/hitting/week_master.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batted Balls Season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "binary = FirefoxBinary(r'C:\\Program Files (x86)\\Mozilla Firefox\\firefox.exe')\n",
    "browser = webdriver.Firefox(firefox_binary=binary)\n",
    "page = 0\n",
    "url_list = ['http://www.fangraphs.com/leaderssplits.aspx?splitArr=&strgroup=season&statgroup=3&startDate=2016-04-03&endDate=',\n",
    "       str(day),\n",
    "        '&filter=&position=B&statType=player&autoPt=false&sort=17,1&pg=',\n",
    "       str(page)]\n",
    "url = \"\".join(url_list)\n",
    "browser.get(url)\n",
    "table = None\n",
    "    \n",
    "#pull html table from first page\n",
    "while table == None:\n",
    "    soup = BS(browser.page_source, \"lxml\")\n",
    "    table = soup.find(attrs = {'class':\"table-splits\"})\n",
    "    sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for tr in table.find('thead').findAll('tr'):\n",
    "    headers = [c.text for c in tr.findAll('th')]\n",
    "headers.append('Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "headers = ['#',\n",
    " 'Season',\n",
    " 'Name',\n",
    " 'Team',\n",
    " 'PA',\n",
    " 'GB/FB',\n",
    " 'LD%',\n",
    " 'GB%',\n",
    " 'FB%',\n",
    " 'IFFB%',\n",
    " 'HR/FB',\n",
    " 'IFH%',\n",
    " 'BUH%',\n",
    " 'Pull%',\n",
    " 'Cent%',\n",
    " 'Oppo%',\n",
    " 'Soft%',\n",
    " 'Med%',\n",
    " 'Hard%',\n",
    " 'Date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create list of days to iterate over\n",
    "start = datetime.date(year = 2015, month = 4, day = 5)\n",
    "end = datetime.date(year = 2015, month = 10, day = 4)\n",
    "date_range = []\n",
    "while start <= end:\n",
    "    date_range.append(start)\n",
    "    start += datetime.timedelta(days = 1)\n",
    "\n",
    "# Create master dataframe and open firefox\n",
    "master_df = pd.DataFrame(columns = headers)\n",
    "binary = FirefoxBinary(r'C:\\Program Files (x86)\\Mozilla Firefox\\firefox.exe')\n",
    "browser = webdriver.Firefox(firefox_binary=binary)\n",
    "\n",
    "# iterate through all days in range, and enter in url\n",
    "for day in date_range:\n",
    "    page = 0\n",
    "    url_list = ['http://www.fangraphs.com/leaderssplits.aspx?splitArr=&strgroup=season&statgroup=3&startDate=2015-04-05&endDate=',\n",
    "           str(day),\n",
    "            '&filter=&position=B&statType=player&autoPt=false&sort=17,1&pg=',\n",
    "           str(page)]\n",
    "    url = \"\".join(url_list)\n",
    "    browser.get(url)   \n",
    "    table = None\n",
    "    \n",
    "    #pull html table from first page\n",
    "    while table == None:\n",
    "        soup = BS(browser.page_source, \"lxml\")\n",
    "        table = soup.find(attrs = {'class':\"table-splits\"})\n",
    "        sleep(1)\n",
    "    body = table.find('tbody')\n",
    "    if body != None:\n",
    "        rows = body.findAll('tr')\n",
    "    else:\n",
    "        continue\n",
    "    \n",
    "    #parses data and appends to master dataframe\n",
    "    data = []\n",
    "    for tr in rows:\n",
    "        cols = tr.findAll('td')\n",
    "        row_text = [c.text for c in cols]\n",
    "        row_text.append(day)\n",
    "        data.append(row_text)\n",
    "    data_df = pd.DataFrame(data, columns=headers)\n",
    "    master_df = master_df.append(data_df)\n",
    "    \n",
    "    #close stupid ad getting in the way\n",
    "    \n",
    "    \n",
    "    #iterate through all pages for given day\n",
    "    page = int(soup.find('span', attrs = {'class':\"table-control-total\"}).text)\n",
    "    for p in range(1,page):\n",
    "        \n",
    "        #scroll to bottom of page to prevent ad intereference\n",
    "        browser.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        \n",
    "        #click next button\n",
    "        browser.find_element_by_class_name('material-icons' and 'next').click()\n",
    "        sleep(1)\n",
    "        \n",
    "        #parses data and appends to master dataframe\n",
    "        data = []\n",
    "        soup = BS(browser.page_source, \"lxml\")\n",
    "        table = soup.find(attrs = {'class':\"table-splits\"})\n",
    "        body = table.find('tbody')\n",
    "        if body != None:\n",
    "            rows = body.findAll('tr')\n",
    "        else:\n",
    "            continue\n",
    "        for tr in rows:\n",
    "            cols = tr.findAll('td')\n",
    "            row_text = [c.text for c in cols]\n",
    "            row_text.append(day)\n",
    "            data.append(row_text)\n",
    "        data_df = pd.DataFrame(data, columns=headers)\n",
    "        master_df = master_df.append(data_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "master_df.to_csv('data/hitting/season_batted_balls_master.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "master_df = pd.DataFrame(columns = headers)\n",
    "for file in os.listdir('data/hitting/'):\n",
    "    if file.startswith('season_batted_balls'):\n",
    "        master_df = master_df.append(pd.read_csv('data/hitting/'+file, index_col = 0))\n",
    "master_df.to_csv('data/hitting/season_batted_balls_master.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batted Balls 7 days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "headers = ['#',\n",
    " 'Season',\n",
    " 'Name',\n",
    " 'Team',\n",
    " 'PA',\n",
    " 'GB/FB',\n",
    " 'LD%',\n",
    " 'GB%',\n",
    " 'FB%',\n",
    " 'IFFB%',\n",
    " 'HR/FB',\n",
    " 'IFH%',\n",
    " 'BUH%',\n",
    " 'Pull%',\n",
    " 'Cent%',\n",
    " 'Oppo%',\n",
    " 'Soft%',\n",
    " 'Med%',\n",
    " 'Hard%',\n",
    " 'Date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "WebDriverException",
     "evalue": "Message: Failed to decode response from marionette\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mWebDriverException\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-50-e6ddb56a650f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[1;31m#parses data and appends to master dataframe\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0msoup\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBS\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbrowser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpage_source\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"lxml\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m         \u001b[0mtable\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msoup\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mattrs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'class'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;34m\"table-splits\"\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0mbody\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtable\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'tbody'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Program Files\\Anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mpage_source\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    499\u001b[0m             \u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpage_source\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m         \"\"\"\n\u001b[0;32m--> 501\u001b[0;31m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCommand\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGET_PAGE_SOURCE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'value'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    502\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Program Files\\Anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, driver_command, params)\u001b[0m\n\u001b[1;32m    234\u001b[0m         \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommand_executor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdriver_command\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 236\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_response\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    237\u001b[0m             response['value'] = self._unwrap_value(\n\u001b[1;32m    238\u001b[0m                 response.get('value', None))\n",
      "\u001b[0;32mC:\\Program Files\\Anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py\u001b[0m in \u001b[0;36mcheck_response\u001b[0;34m(self, response)\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mexception_class\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mUnexpectedAlertPresentException\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;34m'alert'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'alert'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'text'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 192\u001b[0;31m         \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    193\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_value_or_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mWebDriverException\u001b[0m: Message: Failed to decode response from marionette\n"
     ]
    }
   ],
   "source": [
    "# Create list of days to iterate over\n",
    "start = datetime.date(year = 2015, month = 6, day = 9)\n",
    "end = datetime.date(year = 2015, month = 9, day = 27)\n",
    "date_range = []\n",
    "while start <= end:\n",
    "    date_range.append(start)\n",
    "    start += datetime.timedelta(days = 1)\n",
    "\n",
    "# Create master dataframe and open firefox\n",
    "master_df = pd.DataFrame(columns = headers)\n",
    "binary = FirefoxBinary(r'C:\\Program Files (x86)\\Mozilla Firefox\\firefox.exe')\n",
    "browser = webdriver.Firefox(firefox_binary=binary)\n",
    "\n",
    "# iterate through all days in range, and enter in url\n",
    "for day in date_range:\n",
    "    page = 0\n",
    "    url_list = ['http://www.fangraphs.com/leaderssplits.aspx?splitArr=&strgroup=season&statgroup=3&startDate=',\n",
    "           str(day),'&endDate=',str(day + datetime.timedelta(days = 7)),\n",
    "            '&filter=&position=B&statType=player&autoPt=false&sort=17,1&pg=',\n",
    "           str(page)]\n",
    "    url = \"\".join(url_list)\n",
    "    browser.get(url)   \n",
    "    table = None\n",
    "    \n",
    "    #pull html table from first page\n",
    "    while table == None:\n",
    "        soup = BS(browser.page_source, \"lxml\")\n",
    "        table = soup.find(attrs = {'class':\"table-splits\"})\n",
    "        sleep(1)\n",
    "    body = table.find('tbody')\n",
    "    if body != None:\n",
    "        rows = body.findAll('tr')\n",
    "    else:\n",
    "        continue\n",
    "    \n",
    "    #parses data and appends to master dataframe\n",
    "    data = []\n",
    "    for tr in rows:\n",
    "        cols = tr.findAll('td')\n",
    "        row_text = [c.text for c in cols]\n",
    "        row_text.append(day + datetime.timedelta(days = 7))\n",
    "        data.append(row_text)\n",
    "    data_df = pd.DataFrame(data, columns=headers)\n",
    "    master_df = master_df.append(data_df)\n",
    "    \n",
    "    #iterate through all pages for given day\n",
    "    page = int(soup.find('span', attrs = {'class':\"table-control-total\"}).text)\n",
    "    for p in range(1,page):\n",
    "        \n",
    "        #scroll to bottom of page to prevent ad intereference\n",
    "        browser.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        \n",
    "        browser.find_element_by_class_name('material-icons' and 'next').click()\n",
    "        sleep(1)\n",
    "        \n",
    "        #parses data and appends to master dataframe\n",
    "        data = []\n",
    "        soup = BS(browser.page_source, \"lxml\")\n",
    "        table = soup.find(attrs = {'class':\"table-splits\"})\n",
    "        body = table.find('tbody')\n",
    "        if body != None:\n",
    "            rows = body.findAll('tr')\n",
    "        else:\n",
    "            continue\n",
    "        for tr in rows:\n",
    "            cols = tr.findAll('td')\n",
    "            row_text = [c.text for c in cols]\n",
    "            row_text.append(day + datetime.timedelta(days = 7))\n",
    "            data.append(row_text)\n",
    "        data_df = pd.DataFrame(data, columns=headers)\n",
    "        master_df = master_df.append(data_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "master_df.to_csv('data/hitting/past_7_batted_balls_master.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "master_df = pd.DataFrame(columns = headers)\n",
    "for file in os.listdir('data/hitting/'):\n",
    "    if file.startswith('past_7_batted_balls'):\n",
    "        master_df = master_df.append(pd.read_csv('data/hitting/'+file, index_col = 0))\n",
    "master_df.to_csv('data/hitting/past_7_batted_balls_master.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Team\n",
    "### Season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "binary = FirefoxBinary(r'C:\\Program Files (x86)\\Mozilla Firefox\\firefox.exe')\n",
    "browser = webdriver.Firefox(firefox_binary=binary)\n",
    "page = 0\n",
    "url_list = ['http://www.fangraphs.com/leaderssplits.aspx?splitArr=&strgroup=season&statgroup=2&startDate=2016-04-03&endDate=',\n",
    "           str(day),\n",
    "            '&filter=&position=B&statType=team&autoPt=false&sort=15,1&pg=',\n",
    "           str(page)]\n",
    "url = \"\".join(url_list)\n",
    "browser.get(url)   \n",
    "table = None\n",
    "\n",
    "#pull html table from first page\n",
    "while table == None:\n",
    "    soup = BS(browser.page_source, \"lxml\")\n",
    "    table = soup.find(attrs = {'class':\"table-splits\"})\n",
    "    sleep(1)\n",
    "for tr in table.find('thead').findAll('tr'):\n",
    "    headers = [c.text for c in tr.findAll('th')]\n",
    "headers.append('Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "headers = ['#',\n",
    " 'Season',\n",
    " 'Team',\n",
    " 'PA',\n",
    " 'BB%',\n",
    " 'K%',\n",
    " 'BB/K',\n",
    " 'AVG',\n",
    " 'OBP',\n",
    " 'SLG',\n",
    " 'OPS',\n",
    " 'ISO',\n",
    " 'BABIP',\n",
    " 'wRC',\n",
    " 'wRAA',\n",
    " 'wOBA',\n",
    " 'wRC+',\n",
    " 'Date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create list of days to iterate over\n",
    "start = datetime.date(year = 2015, month = 4, day = 5)\n",
    "end = datetime.date(year = 2015, month = 10, day = 4)\n",
    "date_range = []\n",
    "while start <= end:\n",
    "    date_range.append(start)\n",
    "    start += datetime.timedelta(days = 1)\n",
    "\n",
    "# Create master dataframe and open firefox\n",
    "master_df = pd.DataFrame(columns = headers)\n",
    "binary = FirefoxBinary(r'C:\\Program Files (x86)\\Mozilla Firefox\\firefox.exe')\n",
    "browser = webdriver.Firefox(firefox_binary=binary)\n",
    "\n",
    "# iterate through all days in range, and enter in url\n",
    "for day in date_range:\n",
    "    page = 0\n",
    "    url_list = ['http://www.fangraphs.com/leaderssplits.aspx?splitArr=&strgroup=season&statgroup=2&startDate=2015-04-05&endDate=',\n",
    "           str(day),\n",
    "            '&filter=&position=B&statType=team&autoPt=false&sort=15,1&pg=',\n",
    "           str(page)]\n",
    "    url = \"\".join(url_list)\n",
    "    browser.get(url)   \n",
    "    table = None\n",
    "    \n",
    "    #pull html table from first page\n",
    "    while table == None:\n",
    "        soup = BS(browser.page_source, \"lxml\")\n",
    "        table = soup.find(attrs = {'class':\"table-splits\"})\n",
    "        sleep(1)\n",
    "    body = table.find('tbody')\n",
    "    if body != None:\n",
    "        rows = body.findAll('tr')\n",
    "    else:\n",
    "        continue\n",
    "    \n",
    "    #parses data and appends to master dataframe\n",
    "    data = []\n",
    "    for tr in rows:\n",
    "        cols = tr.findAll('td')\n",
    "        row_text = [c.text for c in cols]\n",
    "        row_text.append(day)\n",
    "        data.append(row_text)\n",
    "    data_df = pd.DataFrame(data, columns=headers)\n",
    "    master_df = master_df.append(data_df)\n",
    "    \n",
    "    #close stupid ad getting in the way\n",
    "    \n",
    "    \n",
    "    #iterate through all pages for given day\n",
    "    page = int(soup.find('span', attrs = {'class':\"table-control-total\"}).text)\n",
    "    for p in range(1,page):\n",
    "        \n",
    "        #scroll to bottom of page to prevent ad intereference\n",
    "        browser.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        \n",
    "        #click next button\n",
    "        browser.find_element_by_class_name('material-icons' and 'next').click()\n",
    "        sleep(1)\n",
    "        \n",
    "        #parses data and appends to master dataframe\n",
    "        data = []\n",
    "        soup = BS(browser.page_source, \"lxml\")\n",
    "        table = soup.find(attrs = {'class':\"table-splits\"})\n",
    "        body = table.find('tbody')\n",
    "        if body != None:\n",
    "            rows = body.findAll('tr')\n",
    "        else:\n",
    "            continue\n",
    "        for tr in rows:\n",
    "            cols = tr.findAll('td')\n",
    "            row_text = [c.text for c in cols]\n",
    "            row_text.append(day)\n",
    "            data.append(row_text)\n",
    "        data_df = pd.DataFrame(data, columns=headers)\n",
    "        master_df = master_df.append(data_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "master_df.to_csv('data/hitting/team_season_master.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "master_df = pd.DataFrame(columns = headers)\n",
    "for file in os.listdir('data/hitting/'):\n",
    "    if file.startswith('team_season'):\n",
    "        master_df = master_df.append(pd.read_csv('data/hitting/'+file, index_col = 0))\n",
    "master_df.to_csv('data/hitting/team_season_master.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Past 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create list of days to iterate over\n",
    "start = datetime.date(year = 2015, month = 4, day = 5)\n",
    "end = datetime.date(year = 2015, month = 9, day = 27)\n",
    "date_range = []\n",
    "while start <= end:\n",
    "    date_range.append(start)\n",
    "    start += datetime.timedelta(days = 1)\n",
    "\n",
    "# Create master dataframe and open firefox\n",
    "master_df = pd.DataFrame(columns = headers)\n",
    "binary = FirefoxBinary(r'C:\\Program Files (x86)\\Mozilla Firefox\\firefox.exe')\n",
    "browser = webdriver.Firefox(firefox_binary=binary)\n",
    "\n",
    "# iterate through all days in range, and enter in url\n",
    "for day in date_range:\n",
    "    page = 0\n",
    "    url_list = ['http://www.fangraphs.com/leaderssplits.aspx?splitArr=&strgroup=season&statgroup=2&startDate=',\n",
    "           str(day),'&endDate=',str(day + datetime.timedelta(days = 7)),\n",
    "            '&filter=&position=B&statType=team&autoPt=false&sort=15,1&pg=',\n",
    "           str(page)]\n",
    "    url = \"\".join(url_list)\n",
    "    browser.get(url)   \n",
    "    table = None\n",
    "    \n",
    "    #pull html table from first page\n",
    "    while table == None:\n",
    "        soup = BS(browser.page_source, \"lxml\")\n",
    "        table = soup.find(attrs = {'class':\"table-splits\"})\n",
    "        sleep(1)\n",
    "    body = table.find('tbody')\n",
    "    if body != None:\n",
    "        rows = body.findAll('tr')\n",
    "    else:\n",
    "        continue\n",
    "    \n",
    "    #parses data and appends to master dataframe\n",
    "    data = []\n",
    "    for tr in rows:\n",
    "        cols = tr.findAll('td')\n",
    "        row_text = [c.text for c in cols]\n",
    "        row_text.append(day + datetime.timedelta(days = 7))\n",
    "        data.append(row_text)\n",
    "    data_df = pd.DataFrame(data, columns=headers)\n",
    "    master_df = master_df.append(data_df)\n",
    "    \n",
    "    #iterate through all pages for given day\n",
    "    page = int(soup.find('span', attrs = {'class':\"table-control-total\"}).text)\n",
    "    for p in range(1,page):\n",
    "        \n",
    "        #scroll to bottom of page to prevent ad intereference\n",
    "        browser.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        \n",
    "        browser.find_element_by_class_name('material-icons' and 'next').click()\n",
    "        sleep(1)\n",
    "        \n",
    "        #parses data and appends to master dataframe\n",
    "        data = []\n",
    "        soup = BS(browser.page_source, \"lxml\")\n",
    "        table = soup.find(attrs = {'class':\"table-splits\"})\n",
    "        body = table.find('tbody')\n",
    "        if body != None:\n",
    "            rows = body.findAll('tr')\n",
    "        else:\n",
    "            continue\n",
    "        for tr in rows:\n",
    "            cols = tr.findAll('td')\n",
    "            row_text = [c.text for c in cols]\n",
    "            row_text.append(day + datetime.timedelta(days = 7))\n",
    "            data.append(row_text)\n",
    "        data_df = pd.DataFrame(data, columns=headers)\n",
    "        master_df = master_df.append(data_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "master_df.to_csv('data/hitting/team_past7_master.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "master_df = pd.DataFrame(columns = headers)\n",
    "for file in os.listdir('data/hitting/'):\n",
    "    if file.startswith('team_past7'):\n",
    "        master_df = master_df.append(pd.read_csv('data/hitting/'+file, index_col = 0))\n",
    "master_df.to_csv('data/hitting/team_past7_master.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pitching\n",
    "## Home Season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for tr in table.find('thead').findAll('tr'):\n",
    "    headers = [c.text for c in tr.findAll('th')]\n",
    "headers.append('Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "headers = ['#',\n",
    " 'Season',\n",
    " 'Name',\n",
    " 'Team',\n",
    " 'IP',\n",
    " 'TBF',\n",
    " 'K/9',\n",
    " 'BB/9',\n",
    " 'K/BB',\n",
    " 'HR/9',\n",
    " 'K%',\n",
    " 'BB%',\n",
    " 'K-BB%',\n",
    " 'AVG',\n",
    " 'WHIP',\n",
    " 'BABIP',\n",
    " 'LOB%',\n",
    " 'FIP',\n",
    " 'xFIP',\n",
    " 'Date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create list of days to iterate over\n",
    "start = datetime.date(year = 2015, month = 4, day = 5)\n",
    "end = datetime.date(year = 2015, month = 10, day = 4)\n",
    "date_range = []\n",
    "while start <= end:\n",
    "    date_range.append(start)\n",
    "    start += datetime.timedelta(days = 1)\n",
    "\n",
    "# Create master dataframe and open firefox\n",
    "master_df = pd.DataFrame(columns = headers)\n",
    "binary = FirefoxBinary(r'C:\\Program Files (x86)\\Mozilla Firefox\\firefox.exe')\n",
    "browser = webdriver.Firefox(firefox_binary=binary)\n",
    "\n",
    "# iterate through all days in range, and enter in url\n",
    "for day in date_range:\n",
    "    page = 0\n",
    "    url_list = ['http://www.fangraphs.com/leaderssplits.aspx?splitArr=9&strgroup=season&statgroup=2&startDate=2015-04-05&endDate=',\n",
    "           str(day),\n",
    "            '&filter=&position=P&statType=player&autoPt=false&sort=17,-1&pg=',\n",
    "           str(page)]\n",
    "    url = \"\".join(url_list)\n",
    "    browser.get(url)   \n",
    "    table = None\n",
    "    \n",
    "    #pull html table from first page\n",
    "    while table == None:\n",
    "        soup = BS(browser.page_source, \"lxml\")\n",
    "        table = soup.find(attrs = {'class':\"table-splits\"})\n",
    "        sleep(1)\n",
    "    body = table.find('tbody')\n",
    "    if body != None:\n",
    "        rows = body.findAll('tr')\n",
    "    else:\n",
    "        continue\n",
    "    \n",
    "    #parses data and appends to master dataframe\n",
    "    data = []\n",
    "    for tr in rows:\n",
    "        cols = tr.findAll('td')\n",
    "        row_text = [c.text for c in cols]\n",
    "        row_text.append(day)\n",
    "        data.append(row_text)\n",
    "    data_df = pd.DataFrame(data, columns=headers)\n",
    "    master_df = master_df.append(data_df)\n",
    "    \n",
    "    #iterate through all pages for given day\n",
    "    page = int(soup.find('span', attrs = {'class':\"table-control-total\"}).text)\n",
    "    for p in range(1,page):\n",
    "        #scroll to bottom of page to prevent ad intereference\n",
    "        browser.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        \n",
    "        browser.find_element_by_class_name('material-icons' and 'next').click()\n",
    "        sleep(1)\n",
    "        \n",
    "        #parses data and appends to master dataframe\n",
    "        data = []\n",
    "        soup = BS(browser.page_source, \"lxml\")\n",
    "        table = soup.find(attrs = {'class':\"table-splits\"})\n",
    "        body = table.find('tbody')\n",
    "        if body != None:\n",
    "            rows = body.findAll('tr')\n",
    "        else:\n",
    "            continue\n",
    "        for tr in rows:\n",
    "            cols = tr.findAll('td')\n",
    "            row_text = [c.text for c in cols]\n",
    "            row_text.append(day)\n",
    "            data.append(row_text)\n",
    "        data_df = pd.DataFrame(data, columns=headers)\n",
    "        master_df = master_df.append(data_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "master_df.to_csv('data/pitching/season_home_master.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "master_df = pd.DataFrame(columns = headers)\n",
    "for file in os.listdir('data/pitching/'):\n",
    "    if file.startswith('season_home'):\n",
    "        master_df = master_df.append(pd.read_csv('data/pitching/'+file, index_col = 0))\n",
    "master_df.to_csv('data/pitching/season_home_master.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Away"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create list of days to iterate over\n",
    "start = datetime.date(year = 2015, month = 4, day = 5)\n",
    "end = datetime.date(year = 2015, month = 10, day = 4)\n",
    "date_range = []\n",
    "while start <= end:\n",
    "    date_range.append(start)\n",
    "    start += datetime.timedelta(days = 1)\n",
    "\n",
    "# Create master dataframe and open firefox\n",
    "master_df = pd.DataFrame(columns = headers)\n",
    "binary = FirefoxBinary(r'C:\\Program Files (x86)\\Mozilla Firefox\\firefox.exe')\n",
    "browser = webdriver.Firefox(firefox_binary=binary)\n",
    "\n",
    "# iterate through all days in range, and enter in url\n",
    "for day in date_range:\n",
    "    page = 0\n",
    "    url_list = ['http://www.fangraphs.com/leaderssplits.aspx?splitArr=10&strgroup=season&statgroup=2&startDate=2015-04-05&endDate=',\n",
    "           str(day),\n",
    "            '&filter=&position=P&statType=player&autoPt=false&sort=17,-1&pg=',\n",
    "           str(page)]\n",
    "    url = \"\".join(url_list)\n",
    "    browser.get(url)   \n",
    "    table = None\n",
    "    \n",
    "    #pull html table from first page\n",
    "    while table == None:\n",
    "        soup = BS(browser.page_source, \"lxml\")\n",
    "        table = soup.find(attrs = {'class':\"table-splits\"})\n",
    "        sleep(1)\n",
    "    body = table.find('tbody')\n",
    "    if body != None:\n",
    "        rows = body.findAll('tr')\n",
    "    else:\n",
    "        continue\n",
    "    \n",
    "    #parses data and appends to master dataframe\n",
    "    data = []\n",
    "    for tr in rows:\n",
    "        cols = tr.findAll('td')\n",
    "        row_text = [c.text for c in cols]\n",
    "        row_text.append(day)\n",
    "        data.append(row_text)\n",
    "    data_df = pd.DataFrame(data, columns=headers)\n",
    "    master_df = master_df.append(data_df)\n",
    "    \n",
    "    #iterate through all pages for given day\n",
    "    page = int(soup.find('span', attrs = {'class':\"table-control-total\"}).text)\n",
    "    for p in range(1,page):\n",
    "        #scroll to bottom of page to prevent ad intereference\n",
    "        browser.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")    \n",
    "        \n",
    "        browser.find_element_by_class_name('material-icons' and 'next').click()\n",
    "        sleep(1)\n",
    "        \n",
    "        #parses data and appends to master dataframe\n",
    "        data = []\n",
    "        soup = BS(browser.page_source, \"lxml\")\n",
    "        table = soup.find(attrs = {'class':\"table-splits\"})\n",
    "        body = table.find('tbody')\n",
    "        if body != None:\n",
    "            rows = body.findAll('tr')\n",
    "        else:\n",
    "            continue\n",
    "        for tr in rows:\n",
    "            cols = tr.findAll('td')\n",
    "            row_text = [c.text for c in cols]\n",
    "            row_text.append(day)\n",
    "            data.append(row_text)\n",
    "        data_df = pd.DataFrame(data, columns=headers)\n",
    "        master_df = master_df.append(data_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "master_df.to_csv('data/pitching/season_away_master.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "master_df = pd.DataFrame(columns = headers)\n",
    "for file in os.listdir('data/pitching/'):\n",
    "    if file.startswith('season_away'):\n",
    "        master_df = master_df.append(pd.read_csv('data/pitching/'+file, index_col = 0))\n",
    "master_df.to_csv('data/pitching/season_away_master.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Past Three Starts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.date(2015, 9, 17)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datetime.date(year = 2015, month = 10, day = 4) - datetime.timedelta(days = 17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create list of days to iterate over\n",
    "start = datetime.date(year = 2015, month = 3, day = 19)\n",
    "end = datetime.date(year = 2015, month = 9, day = 17)\n",
    "date_range = []\n",
    "while start <= end:\n",
    "    date_range.append(start)\n",
    "    start += datetime.timedelta(days = 1)\n",
    "\n",
    "# Create master dataframe and open firefox\n",
    "master_df = pd.DataFrame(columns = headers)\n",
    "binary = FirefoxBinary(r'C:\\Program Files (x86)\\Mozilla Firefox\\firefox.exe')\n",
    "browser = webdriver.Firefox(firefox_binary=binary)\n",
    "\n",
    "# iterate through all days in range, and enter in url\n",
    "for day in date_range:\n",
    "    page = 0\n",
    "    url_list = ['http://www.fangraphs.com/leaderssplits.aspx?splitArr=&strgroup=season&statgroup=2&startDate=',\n",
    "           str(day),'&endDate=',str(day + datetime.timedelta(days = 17)),\n",
    "            '&filter=&position=P&statType=player&autoPt=false&sort=17,-1&pg=',\n",
    "           str(page)]\n",
    "    url = \"\".join(url_list)\n",
    "    browser.get(url)   \n",
    "    table = None\n",
    "    \n",
    "    #pull html table from first page\n",
    "    while table == None:\n",
    "        soup = BS(browser.page_source, \"lxml\")\n",
    "        table = soup.find(attrs = {'class':\"table-splits\"})\n",
    "        sleep(1)\n",
    "    body = table.find('tbody')\n",
    "    if body != None:\n",
    "        rows = body.findAll('tr')\n",
    "    else:\n",
    "        continue\n",
    "    \n",
    "    #parses data and appends to master dataframe\n",
    "    data = []\n",
    "    for tr in rows:\n",
    "        cols = tr.findAll('td')\n",
    "        row_text = [c.text for c in cols]\n",
    "        row_text.append(day + datetime.timedelta(days = 17))\n",
    "        data.append(row_text)\n",
    "    data_df = pd.DataFrame(data, columns=headers)\n",
    "    master_df = master_df.append(data_df)\n",
    "    \n",
    "    #iterate through all pages for given day\n",
    "    page = int(soup.find('span', attrs = {'class':\"table-control-total\"}).text)\n",
    "    for p in range(1,page):\n",
    "        \n",
    "        browser.find_element_by_class_name('material-icons' and 'next').click()\n",
    "        sleep(1)\n",
    "        \n",
    "        #parses data and appends to master dataframe\n",
    "        data = []\n",
    "        soup = BS(browser.page_source, \"lxml\")\n",
    "        table = soup.find(attrs = {'class':\"table-splits\"})\n",
    "        body = table.find('tbody')\n",
    "        if body != None:\n",
    "            rows = body.findAll('tr')\n",
    "        else:\n",
    "            continue\n",
    "        for tr in rows:\n",
    "            cols = tr.findAll('td')\n",
    "            row_text = [c.text for c in cols]\n",
    "            row_text.append(day + datetime.timedelta(days = 17))\n",
    "            data.append(row_text)\n",
    "        data_df = pd.DataFrame(data, columns=headers)\n",
    "        master_df = master_df.append(data_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "master_df.to_csv('data/pitching/past_3games_master.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "master_df = pd.DataFrame(columns = headers)\n",
    "for file in os.listdir('data/pitching/'):\n",
    "    if file.startswith('past_3games'):\n",
    "        master_df = master_df.append(pd.read_csv('data/pitching/'+file, index_col = 0))\n",
    "master_df.to_csv('data/pitching/past_3games_master.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batted Balls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "binary = FirefoxBinary(r'C:\\Program Files (x86)\\Mozilla Firefox\\firefox.exe')\n",
    "browser = webdriver.Firefox(firefox_binary=binary)\n",
    "url_list = ['http://www.fangraphs.com/leaderssplits.aspx?splitArr=&strgroup=season&statgroup=3&startDate=2016-04-08&endDate=',\n",
    "       str(day),\n",
    "        '&filter=&position=P&statType=player&autoPt=true&sort=18,-1&pg=',\n",
    "       str(page)]\n",
    "url = \"\".join(url_list)\n",
    "browser.get(url)   \n",
    "table = None\n",
    "\n",
    "#pull html table from first page\n",
    "while table == None:\n",
    "    soup = BS(browser.page_source, \"lxml\")\n",
    "    table = soup.find(attrs = {'class':\"table-splits\"})\n",
    "    sleep(1)\n",
    "for tr in table.find('thead').findAll('tr'):\n",
    "    headers = [c.text for c in tr.findAll('th')]\n",
    "headers.append('Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "headers = ['#',\n",
    " 'Season',\n",
    " 'Name',\n",
    " 'Team',\n",
    " 'IP',\n",
    " 'TBF',\n",
    " 'GB/FB',\n",
    " 'LD%',\n",
    " 'GB%',\n",
    " 'FB%',\n",
    " 'IFFB%',\n",
    " 'HR/FB',\n",
    " 'IFH%',\n",
    " 'BUH%',\n",
    " 'Pull%',\n",
    " 'Cent%',\n",
    " 'Oppo%',\n",
    " 'Soft%',\n",
    " 'Med%',\n",
    " 'Hard%',\n",
    " 'Date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create list of days to iterate over\n",
    "start = datetime.date(year = 2015, month = 4, day = 5)\n",
    "end = datetime.date(year = 2015, month = 10, day = 4)\n",
    "date_range = []\n",
    "while start <= end:\n",
    "    date_range.append(start)\n",
    "    start += datetime.timedelta(days = 1)\n",
    "\n",
    "# Create master dataframe and open firefox\n",
    "master_df = pd.DataFrame(columns = headers)\n",
    "binary = FirefoxBinary(r'C:\\Program Files (x86)\\Mozilla Firefox\\firefox.exe')\n",
    "browser = webdriver.Firefox(firefox_binary=binary)\n",
    "\n",
    "# iterate through all days in range, and enter in url\n",
    "for day in date_range:\n",
    "    page = 0\n",
    "    url_list = ['http://www.fangraphs.com/leaderssplits.aspx?splitArr=&strgroup=season&statgroup=3&startDate=2015-04-05&endDate=',\n",
    "           str(day),\n",
    "            '&filter=&position=P&statType=player&autoPt=false&sort=18,-1&pg=',\n",
    "           str(page)]\n",
    "    url = \"\".join(url_list)\n",
    "    browser.get(url)   \n",
    "    table = None\n",
    "    \n",
    "    #pull html table from first page\n",
    "    while table == None:\n",
    "        soup = BS(browser.page_source, \"lxml\")\n",
    "        table = soup.find(attrs = {'class':\"table-splits\"})\n",
    "        sleep(1)\n",
    "    body = table.find('tbody')\n",
    "    if body != None:\n",
    "        rows = body.findAll('tr')\n",
    "    else:\n",
    "        continue\n",
    "    \n",
    "    #parses data and appends to master dataframe\n",
    "    data = []\n",
    "    for tr in rows:\n",
    "        cols = tr.findAll('td')\n",
    "        row_text = [c.text for c in cols]\n",
    "        row_text.append(day)\n",
    "        data.append(row_text)\n",
    "    data_df = pd.DataFrame(data, columns=headers)\n",
    "    master_df = master_df.append(data_df)\n",
    "    \n",
    "    #close stupid ad getting in the way\n",
    "    \n",
    "    \n",
    "    #iterate through all pages for given day\n",
    "    page = int(soup.find('span', attrs = {'class':\"table-control-total\"}).text)\n",
    "    for p in range(1,page):\n",
    "        \n",
    "        #scroll to bottom of page to prevent ad intereference\n",
    "        browser.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        \n",
    "        #click next button\n",
    "        browser.find_element_by_class_name('material-icons' and 'next').click()\n",
    "        sleep(1)\n",
    "        \n",
    "        #parses data and appends to master dataframe\n",
    "        data = []\n",
    "        soup = BS(browser.page_source, \"lxml\")\n",
    "        table = soup.find(attrs = {'class':\"table-splits\"})\n",
    "        body = table.find('tbody')\n",
    "        if body != None:\n",
    "            rows = body.findAll('tr')\n",
    "        else:\n",
    "            continue\n",
    "        for tr in rows:\n",
    "            cols = tr.findAll('td')\n",
    "            row_text = [c.text for c in cols]\n",
    "            row_text.append(day)\n",
    "            data.append(row_text)\n",
    "        data_df = pd.DataFrame(data, columns=headers)\n",
    "        master_df = master_df.append(data_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "master_df.to_csv('data/pitching/season_batted_balls_master.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "master_df = pd.DataFrame(columns = headers)\n",
    "for file in os.listdir('data/pitching/'):\n",
    "    if file.startswith('season_batted_balls'):\n",
    "        master_df = master_df.append(pd.read_csv('data/pitching/'+file, index_col = 0))\n",
    "master_df.to_csv('data/pitching/season_batted_balls_master.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Past Three Starts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create list of days to iterate over\n",
    "start = datetime.date(year = 2015, month = 3, day = 19)\n",
    "end = datetime.date(year = 2015, month = 9, day = 17)\n",
    "date_range = []\n",
    "while start <= end:\n",
    "    date_range.append(start)\n",
    "    start += datetime.timedelta(days = 1)\n",
    "\n",
    "# Create master dataframe and open firefox\n",
    "master_df = pd.DataFrame(columns = headers)\n",
    "binary = FirefoxBinary(r'C:\\Program Files (x86)\\Mozilla Firefox\\firefox.exe')\n",
    "browser = webdriver.Firefox(firefox_binary=binary)\n",
    "\n",
    "# iterate through all days in range, and enter in url\n",
    "for day in date_range:\n",
    "    page = 0\n",
    "    url_list = ['http://www.fangraphs.com/leaderssplits.aspx?splitArr=&strgroup=season&statgroup=3&startDate=',\n",
    "           str(day),'&endDate=',str(day + datetime.timedelta(days = 17)),\n",
    "            '&filter=&position=P&statType=player&autoPt=false&sort=18,-1&pg=',\n",
    "           str(page)]\n",
    "    url = \"\".join(url_list)\n",
    "    browser.get(url)   \n",
    "    table = None\n",
    "    \n",
    "    #pull html table from first page\n",
    "    while table == None:\n",
    "        soup = BS(browser.page_source, \"lxml\")\n",
    "        table = soup.find(attrs = {'class':\"table-splits\"})\n",
    "        sleep(1)\n",
    "    body = table.find('tbody')\n",
    "    if body != None:\n",
    "        rows = body.findAll('tr')\n",
    "    else:\n",
    "        continue\n",
    "    \n",
    "    #parses data and appends to master dataframe\n",
    "    data = []\n",
    "    for tr in rows:\n",
    "        cols = tr.findAll('td')\n",
    "        row_text = [c.text for c in cols]\n",
    "        row_text.append(day + datetime.timedelta(days = 17))\n",
    "        data.append(row_text)\n",
    "    data_df = pd.DataFrame(data, columns=headers)\n",
    "    master_df = master_df.append(data_df)\n",
    "    \n",
    "    #iterate through all pages for given day\n",
    "    page = int(soup.find('span', attrs = {'class':\"table-control-total\"}).text)\n",
    "    for p in range(1,page):\n",
    "        \n",
    "        #scroll to bottom of page to prevent ad intereference\n",
    "        browser.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")        \n",
    "        \n",
    "        browser.find_element_by_class_name('material-icons' and 'next').click()\n",
    "        sleep(1)\n",
    "        \n",
    "        #parses data and appends to master dataframe\n",
    "        data = []\n",
    "        soup = BS(browser.page_source, \"lxml\")\n",
    "        table = soup.find(attrs = {'class':\"table-splits\"})\n",
    "        body = table.find('tbody')\n",
    "        if body != None:\n",
    "            rows = body.findAll('tr')\n",
    "        else:\n",
    "            continue\n",
    "        for tr in rows:\n",
    "            cols = tr.findAll('td')\n",
    "            row_text = [c.text for c in cols]\n",
    "            row_text.append(day + datetime.timedelta(days = 17))\n",
    "            data.append(row_text)\n",
    "        data_df = pd.DataFrame(data, columns=headers)\n",
    "        master_df = master_df.append(data_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "master_df.to_csv('data/pitching/past_3games_batted_balls_master.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "master_df = pd.DataFrame(columns = headers)\n",
    "for file in os.listdir('data/pitching/'):\n",
    "    if file.startswith('past_3games_batted_balls'):\n",
    "        master_df = master_df.append(pd.read_csv('data/pitching/'+file, index_col = 0))\n",
    "master_df.to_csv('data/pitching/past_3games_batted_balls_master.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bullpen\n",
    "### Season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "binary = FirefoxBinary(r'C:\\Program Files (x86)\\Mozilla Firefox\\firefox.exe')\n",
    "browser = webdriver.Firefox(firefox_binary=binary)\n",
    "url_list = ['http://www.fangraphs.com/leaderssplits.aspx?splitArr=43&strgroup=season&statgroup=2&startDate=2016-04-03&endDate=',\n",
    "       str(day),\n",
    "        '&filter=&position=P&statType=team&autoPt=false&sort=16,-1&pg=',\n",
    "       str(page)]\n",
    "url = \"\".join(url_list)\n",
    "browser.get(url)   \n",
    "table = None\n",
    "\n",
    "#pull html table from first page\n",
    "while table == None:\n",
    "    soup = BS(browser.page_source, \"lxml\")\n",
    "    table = soup.find(attrs = {'class':\"table-splits\"})\n",
    "    sleep(1)\n",
    "for tr in table.find('thead').findAll('tr'):\n",
    "    headers = [c.text for c in tr.findAll('th')]\n",
    "headers.append('Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "headers = ['#',\n",
    " 'Season',\n",
    " 'Team',\n",
    " 'IP',\n",
    " 'TBF',\n",
    " 'K/9',\n",
    " 'BB/9',\n",
    " 'K/BB',\n",
    " 'HR/9',\n",
    " 'K%',\n",
    " 'BB%',\n",
    " 'K-BB%',\n",
    " 'AVG',\n",
    " 'WHIP',\n",
    " 'BABIP',\n",
    " 'LOB%',\n",
    " 'FIP',\n",
    " 'xFIP',\n",
    " 'Date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create list of days to iterate over\n",
    "start = datetime.date(year = 2015, month = 4, day = 5)\n",
    "end = datetime.date(year = 2015, month = 10, day = 4)\n",
    "date_range = []\n",
    "while start <= end:\n",
    "    date_range.append(start)\n",
    "    start += datetime.timedelta(days = 1)\n",
    "\n",
    "# Create master dataframe and open firefox\n",
    "master_df = pd.DataFrame(columns = headers)\n",
    "binary = FirefoxBinary(r'C:\\Program Files (x86)\\Mozilla Firefox\\firefox.exe')\n",
    "browser = webdriver.Firefox(firefox_binary=binary)\n",
    "\n",
    "# iterate through all days in range, and enter in url\n",
    "for day in date_range:\n",
    "    page = 0\n",
    "    url_list = ['http://www.fangraphs.com/leaderssplits.aspx?splitArr=43&strgroup=season&statgroup=2&startDate=2015-04-05&endDate=',\n",
    "           str(day),\n",
    "            '&filter=&position=P&statType=team&autoPt=false&sort=16,-1&pg=',\n",
    "           str(page)]\n",
    "    url = \"\".join(url_list)\n",
    "    browser.get(url)   \n",
    "    table = None\n",
    "    \n",
    "    #pull html table from first page\n",
    "    while table == None:\n",
    "        soup = BS(browser.page_source, \"lxml\")\n",
    "        table = soup.find(attrs = {'class':\"table-splits\"})\n",
    "        sleep(1)\n",
    "    body = table.find('tbody')\n",
    "    if body != None:\n",
    "        rows = body.findAll('tr')\n",
    "    else:\n",
    "        continue\n",
    "    \n",
    "    #parses data and appends to master dataframe\n",
    "    data = []\n",
    "    for tr in rows:\n",
    "        cols = tr.findAll('td')\n",
    "        row_text = [c.text for c in cols]\n",
    "        row_text.append(day)\n",
    "        data.append(row_text)\n",
    "    data_df = pd.DataFrame(data, columns=headers)\n",
    "    master_df = master_df.append(data_df)\n",
    "    \n",
    "    #close stupid ad getting in the way\n",
    "    \n",
    "    \n",
    "    #iterate through all pages for given day\n",
    "    page = int(soup.find('span', attrs = {'class':\"table-control-total\"}).text)\n",
    "    for p in range(1,page):\n",
    "        \n",
    "        #scroll to bottom of page to prevent ad intereference\n",
    "        browser.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        \n",
    "        #click next button\n",
    "        browser.find_element_by_class_name('material-icons' and 'next').click()\n",
    "        sleep(1)\n",
    "        \n",
    "        #parses data and appends to master dataframe\n",
    "        data = []\n",
    "        soup = BS(browser.page_source, \"lxml\")\n",
    "        table = soup.find(attrs = {'class':\"table-splits\"})\n",
    "        body = table.find('tbody')\n",
    "        if body != None:\n",
    "            rows = body.findAll('tr')\n",
    "        else:\n",
    "            continue\n",
    "        for tr in rows:\n",
    "            cols = tr.findAll('td')\n",
    "            row_text = [c.text for c in cols]\n",
    "            row_text.append(day)\n",
    "            data.append(row_text)\n",
    "        data_df = pd.DataFrame(data, columns=headers)\n",
    "        master_df = master_df.append(data_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "master_df.to_csv('data/pitching/bullpen_season_master.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "master_df = pd.DataFrame(columns = headers)\n",
    "for file in os.listdir('data/pitching/'):\n",
    "    if file.startswith('bullpen_season'):\n",
    "        master_df = master_df.append(pd.read_csv('data/pitching/'+file, index_col = 0))\n",
    "master_df.to_csv('data/pitching/bullpen_season_master.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Past 7 Days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create list of days to iterate over\n",
    "start = datetime.date(year = 2015, month = 4, day = 5)\n",
    "end = datetime.date(year = 2015, month = 9, day = 27)\n",
    "date_range = []\n",
    "while start <= end:\n",
    "    date_range.append(start)\n",
    "    start += datetime.timedelta(days = 1)\n",
    "\n",
    "# Create master dataframe and open firefox\n",
    "master_df = pd.DataFrame(columns = headers)\n",
    "binary = FirefoxBinary(r'C:\\Program Files (x86)\\Mozilla Firefox\\firefox.exe')\n",
    "browser = webdriver.Firefox(firefox_binary=binary)\n",
    "\n",
    "# iterate through all days in range, and enter in url\n",
    "for day in date_range:\n",
    "    page = 0\n",
    "    url_list = ['http://www.fangraphs.com/leaderssplits.aspx?splitArr=43&strgroup=season&statgroup=2&startDate=',\n",
    "           str(day),'&endDate=',str(day + datetime.timedelta(days = 7)),\n",
    "            '&filter=&position=P&statType=team&autoPt=false&sort=16,-1&pg=',\n",
    "           str(page)]\n",
    "    url = \"\".join(url_list)\n",
    "    browser.get(url)   \n",
    "    table = None\n",
    "    \n",
    "    #pull html table from first page\n",
    "    while table == None:\n",
    "        soup = BS(browser.page_source, \"lxml\")\n",
    "        table = soup.find(attrs = {'class':\"table-splits\"})\n",
    "        sleep(1)\n",
    "    body = table.find('tbody')\n",
    "    if body != None:\n",
    "        rows = body.findAll('tr')\n",
    "    else:\n",
    "        continue\n",
    "    \n",
    "    #parses data and appends to master dataframe\n",
    "    data = []\n",
    "    for tr in rows:\n",
    "        cols = tr.findAll('td')\n",
    "        row_text = [c.text for c in cols]\n",
    "        row_text.append(day + datetime.timedelta(days = 7))\n",
    "        data.append(row_text)\n",
    "    data_df = pd.DataFrame(data, columns=headers)\n",
    "    master_df = master_df.append(data_df)\n",
    "    \n",
    "    #iterate through all pages for given day\n",
    "    page = int(soup.find('span', attrs = {'class':\"table-control-total\"}).text)\n",
    "    for p in range(1,page):\n",
    "        \n",
    "        #scroll to bottom of page to prevent ad intereference\n",
    "        browser.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        \n",
    "        browser.find_element_by_class_name('material-icons' and 'next').click()\n",
    "        sleep(1)\n",
    "        \n",
    "        #parses data and appends to master dataframe\n",
    "        data = []\n",
    "        soup = BS(browser.page_source, \"lxml\")\n",
    "        table = soup.find(attrs = {'class':\"table-splits\"})\n",
    "        body = table.find('tbody')\n",
    "        if body != None:\n",
    "            rows = body.findAll('tr')\n",
    "        else:\n",
    "            continue\n",
    "        for tr in rows:\n",
    "            cols = tr.findAll('td')\n",
    "            row_text = [c.text for c in cols]\n",
    "            row_text.append(day + datetime.timedelta(days = 7))\n",
    "            data.append(row_text)\n",
    "        data_df = pd.DataFrame(data, columns=headers)\n",
    "        master_df = master_df.append(data_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "master_df.to_csv('data/pitching/bullpen_past7_master.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "master_df = pd.DataFrame(columns = headers)\n",
    "for file in os.listdir('data/pitching/'):\n",
    "    if file.startswith('bullpen_past7'):\n",
    "        master_df = master_df.append(pd.read_csv('data/pitching/'+file, index_col = 0))\n",
    "master_df.to_csv('data/pitching/bullpen_past7_master.csv')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
